<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pedro J. Aphalo">

<title>9&nbsp; Imaging in UV, VIS and NIR radiation – Field Methods in Plant Photobiology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./design-of-experiments.html" rel="next">
<link href="./quantifying-responses.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-70a47bd5681a7291082a5b9f83d58762.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": true
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./quantifying-radiation.html">Measurements</a></li><li class="breadcrumb-item"><a href="./imaging.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Imaging in UV, VIS and NIR radiation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Field Methods in Plant Photobiology</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface-1ed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface to the 1st edition</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface to the 2nd edition</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contents.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Table of Contents</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./abbreviations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">List of abbreviations and symbols</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Basics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./radiation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Radiation Physics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Radiation-matter Interactions and Optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./light-environment-terrestrial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The UV, VIS and NIR environment above vegetation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./light-environment-plants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The UV, VIS and NIR environment of plants</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Measurements</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantifying-radiation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Quantifying radiation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./leaf-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Quantifying Optical Properties</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantifying-responses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Quantifying plants’ responses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Imaging in UV, VIS and NIR radiation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Design and planning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./design-of-experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Design of Experiments and Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Ensuring reproducibility</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Realization and treatments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./manipulating-radiation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Manipulating UV, VIS and NIR radiation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./plant-cultivation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plant cultivation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">9.1</span> Introduction</a></li>
  <li><a href="#types-of-cameras" id="toc-types-of-cameras" class="nav-link" data-scroll-target="#types-of-cameras"><span class="header-section-number">9.2</span> Types of cameras</a>
  <ul class="collapse">
  <li><a href="#digital-photographic-cameras" id="toc-digital-photographic-cameras" class="nav-link" data-scroll-target="#digital-photographic-cameras"><span class="header-section-number">9.2.1</span> Digital photographic cameras</a></li>
  <li><a href="#head-less-specialised-cameras" id="toc-head-less-specialised-cameras" class="nav-link" data-scroll-target="#head-less-specialised-cameras"><span class="header-section-number">9.2.2</span> Head-less specialised cameras</a></li>
  <li><a href="#spectral-and-hyperspectral-cameras" id="toc-spectral-and-hyperspectral-cameras" class="nav-link" data-scroll-target="#spectral-and-hyperspectral-cameras"><span class="header-section-number">9.2.3</span> Spectral and hyperspectral cameras</a></li>
  <li><a href="#thermal-cameras" id="toc-thermal-cameras" class="nav-link" data-scroll-target="#thermal-cameras"><span class="header-section-number">9.2.4</span> Thermal cameras</a></li>
  </ul></li>
  <li><a href="#objectives" id="toc-objectives" class="nav-link" data-scroll-target="#objectives"><span class="header-section-number">9.3</span> Objectives</a>
  <ul class="collapse">
  <li><a href="#photography-objectives" id="toc-photography-objectives" class="nav-link" data-scroll-target="#photography-objectives"><span class="header-section-number">9.3.1</span> Photography objectives</a></li>
  <li><a href="#objectives-for-uv-and-nir-photography" id="toc-objectives-for-uv-and-nir-photography" class="nav-link" data-scroll-target="#objectives-for-uv-and-nir-photography"><span class="header-section-number">9.3.2</span> Objectives for UV and NIR photography</a></li>
  </ul></li>
  <li><a href="#optical-filters" id="toc-optical-filters" class="nav-link" data-scroll-target="#optical-filters"><span class="header-section-number">9.4</span> Optical filters</a></li>
  <li><a href="#uv-vis-and-nir-radiation-sources" id="toc-uv-vis-and-nir-radiation-sources" class="nav-link" data-scroll-target="#uv-vis-and-nir-radiation-sources"><span class="header-section-number">9.5</span> UV, VIS and NIR radiation sources</a></li>
  <li><a href="#accessories" id="toc-accessories" class="nav-link" data-scroll-target="#accessories"><span class="header-section-number">9.6</span> Accessories</a>
  <ul class="collapse">
  <li><a href="#colour-and-grey-scale-references" id="toc-colour-and-grey-scale-references" class="nav-link" data-scroll-target="#colour-and-grey-scale-references"><span class="header-section-number">9.6.1</span> Colour and grey-scale references</a></li>
  </ul></li>
  <li><a href="#procedures" id="toc-procedures" class="nav-link" data-scroll-target="#procedures"><span class="header-section-number">9.7</span> Procedures</a>
  <ul class="collapse">
  <li><a href="#reproducibility" id="toc-reproducibility" class="nav-link" data-scroll-target="#reproducibility"><span class="header-section-number">9.7.1</span> Reproducibility</a></li>
  <li><a href="#uv-photography" id="toc-uv-photography" class="nav-link" data-scroll-target="#uv-photography"><span class="header-section-number">9.7.2</span> UV photography</a></li>
  <li><a href="#nir-photography" id="toc-nir-photography" class="nav-link" data-scroll-target="#nir-photography"><span class="header-section-number">9.7.3</span> NIR photography</a></li>
  <li><a href="#uvivf" id="toc-uvivf" class="nav-link" data-scroll-target="#uvivf"><span class="header-section-number">9.7.4</span> UVIVF</a></li>
  </ul></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">9.8</span> Further reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./quantifying-radiation.html">Measurements</a></li><li class="breadcrumb-item"><a href="./imaging.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Imaging in UV, VIS and NIR radiation</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Imaging in UV, VIS and NIR radiation</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Equipment and methods</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Pedro J. Aphalo </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggspectra)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyFilters)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyLamps)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyLEDs)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyPlants)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">photon_as_default</span>()</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">Tfr_as_default</span>()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="introduction" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">9.1</span> Introduction</h2>
<p>With some exceptions, producing photographic images, either photo-electronically or photo-chemically, requires a camera, a lens and a light source. To limit the imaging to specific regions of the spectrum, optical filters are used. Illumination can be sunlight or artificial. If artificial it can have a broad spectrum or be limited to a specific range of wavelengths.</p>
<p>Most frequently, landscape and other types of low magnification and even macro photography are based on reflected light. In microscopy it is common to image the light transmited through a specimen. Imaging of fluorescence is also used in the plant sciences in relation to photosyntheis and other pigments, and in microscopy. In this chapter, we exclude high magnification microscopy, and concern with photography at magnifications of less than <span class="math inline">\times 5</span>.</p>
<p>Black and white (grey scale) images contain only brightness information, which can be intuitively mapped also in images obtained at wavelengths invisible to humans. In contrast, colour photographs are intuitively expected to represent colours as seen by humans. When mapping wavelengths invisible to us into colours, the choice of mapping stops being obvious, and different more or less arbitrary mappings can be used. In some cases, the mapping is just accidental, as a consequence of the properties of the R, G, and B filters of image sensors in the UV or NIR regions, wavelengths not taken into account in their design.</p>
<p>This chapter is structured in sections describing cameras, lenses, filters, light sources and accesories. Image editing and special techniques based on image merging are discussed next. These sections are followed by a description of example setups and procedures for UV, VIS, and NIR imaging, fluorescence imaging, as well as macro photography. A whole book could be written on the subject but this chapter intends to be an introduction to imaging methods of special interest to photobiologists.</p>
</section>
<section id="types-of-cameras" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="types-of-cameras"><span class="header-section-number">9.2</span> Types of cameras</h2>
<section id="digital-photographic-cameras" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="digital-photographic-cameras"><span class="header-section-number">9.2.1</span> Digital photographic cameras</h3>
<p>It is usual to call cameras with interchangeable lenses “system cameras” and those with a lens permanently afixed, usually smaller in size and with no or with limited or akward to use manual settings “point-and-shoot” cameras. There are some cameras that do do not fit into these two categories, e.g., with full manual controls and relatively large sensors with no possibility to change lenses. Cameras in these different categories can be useful in scientific research, but not interchangeably. Their advantages and disadvantages determine their suitability. Even smart phone cameras, can occasionally be useful for more than “visual note taking” <a href="#fig-photography-cameras" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>.</p>
<div id="fig-photography-cameras" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-photography-cameras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/om-1-mark-ii-12-40mm-pro-kit-top.webp" class="img-fluid figure-img"></p>
<figcaption>OM-1</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/tough_tg-7_-_techspecs_image.webp" class="img-fluid figure-img"></p>
<figcaption>TG-7</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-photography-cameras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.1: A mirrorless camera (OM-1) with an interchangeable lens and a hardened point-and-shoot camera (TG-7) with a fixed zoom lens,. The OM-1 is splash and dust proof and rated to function from -20 to +40 C, altough in practice can be used at lower temperatures. The TG-7 is named “tough” and designed to work without additional protection both in air and down to a depth of 15 m in water, to survive forces of up 100 kg and falls from a height of 2.1 m.
</figcaption>
</figure>
</div>
<p>Digital cameras sold for amateur and professional photography are self contained: all controls, viewfinder and/or live-view screen, image review and image data storage all take place in-camera. Modern cameras are also capable of complex image processing. These cameras are primarily battery powered althougn some can be in addition powered externally. Most cameras for ordinary photography are designed for imaging reflected visible light. In a few cases, manufacturers have offered versions of these cameras for use in forensics or astronomy, with extended wavelength range (e.g., OM-3 ASTRO Mirrorless Camera, OM-System).</p>
<p>Normal photographic cameras aim at producing images that depict a scene as seen by humans, and, thus, are most sensitive to the central wavelengths of visible light (<span class="math inline">\approx 410-680</span> nm). When producing colour images, image sensors with three colour channels are used, with each channel’s colour response designed to approximately mimic the spectral sensitivity of one of the three photoreceptors participating in human day-time vision. This tight link to human vision also applies to the implementations of colour film, video, TV and computer monitors. Colour printing is more complex as inks are in most cases opaque making their effect on reflection non-additive, but printing also exploits the “deficiencies” of our eyes to trick us into seeing colours.</p>
<p>In the case of monochrome or greyscale (= black and white, BW) photographic films used for everyday photography and the very few monochrome digital photographic cameras available, the images produced aim at depicting the brightness of an scene as seen by humans. <em>In other words, normal photographic and video cameras are designed to work as proxies for human three-chromic vision, not as spectrometers</em>.</p>
<p>Most digital photography cameras capture colour images and have sensors with red, green and blue filters on individual pixels. Monochrome cameras have sensors lacking such filters. So each pixels in the sensor receives more photons. In addition, the lack of filters makes raw image processing straightforward with all individual pixels providing equivalent data. This results in a higher apparent spatial resolution and higher dynamic range. Currently, there are four monochromatic (or greyscale) digital photographic cameras available: Leica M11 Monochrom, Leica Q3 Monochrom, Leica Q2 Monochrom and Pentax K-3 Mark III Monochrome. A monochrome point-and-shoot camera has been announced by Ricoh.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Digital image sensors
</div>
</div>
<div class="callout-body-container callout-body">
<p>Image sensors are two-dimensional arrays of photodetectors. The main determinant of the native wavelength sensitivity is the material used. Most VIS (really 320 to 1000 nm) sensors are made of silicon (Si) using CMOS or CCD approaches. The size of individual photosites and the speed of their readout varies. There is normally a compromise between the number pixels (amount of data to be acquired) and the speed of image acquisition measured in frames per second (fps). The whole sensor array in constructed by etching and deposition similarly to how electronic integrated ciscuits are made. The wavelength range can be constrained with optical filters, on individual photosites, small groups of photosites, or the whole image sensor.</p>
</div>
</div>
<p>The sensors used in photographic cammeras are natively sensitive to wavelengths in the range <span class="math inline">\approx 330-1100</span> nm and the R, G and B filters, do transmit outside the VIS range. At both ends of this range, sensitivity (<span class="math inline">\approx</span> quantum yield) decreases very gradually. In photographic cameras, the wavelength range is constrained by an optical UV and IR cut filter attached to the front of the whole sensor assembly to create a wavelength response closer to that of human vision. Depending on the camera, the shortest wavelengths that are detected by the sensor plus filter combined vary between <span class="math inline">370 nm</span> and <span class="math inline">420 nm</span>, and the longest ones between <span class="math inline">680 nm</span> and <span class="math inline">730 nm</span>. The filters used are frequently absoptive ionic and the cut-in and cut-off, specialy at the NIR end, is gradual, i.e., in most digital photography cameras it is possible to use a <span class="math inline">720 nm</span> long-pass filter to take images in the NIR but only by increasing exposure by orders of magnitude.</p>
<p>It is possible to <em>convert</em> cameras to <em>“full spectrum”</em> (meaning the native sensitivity of the sensor with its R, G and B filters) by replacing the sensor filter with quartz glass or a long-pass filter with a suitable cut-in, such as at 280 nm. In a <em>“full spectrum”</em> converted camera additional filters can be used in front or behind the lens to restrict the wavelength range as needed. Alternatively a camera can be modified to be constitutively sensitive to a especific range of wavelengths installing a wavelength-selective filter onto the sensor.</p>
<p>Conversion involves disassembling the camera but is relatively simple, and costs between 200 € and 500 € depending on the camera model and who does the conversion. In a <em>“full spectrum”</em> or <em>“filter”</em> conversion, the sensor itself in not modified, and the RGB filters remain on the sensors pixels. Several companies, both is the USA and in Europe do conversions, but not all of them are equally reliable.</p>
<p>The conversion of a colour camera into a monochrome camera is much more difficult and there is a risk of damaging the sensor making it unusable, as it involves the removal filters that are part of the sensor itself. Very few companies do this type of conversion, charging from 1200 € to &gt; 1500 €, usually only accepting for conversion specific models or brands of cameras. A <em>“full spectrum monochrome”</em> conversion is also possible, either by modifying a natively monochrome camera or by removal of R, G and B filters plus replacement of Uv and IR cut filter.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>False colour in UV-A and NIR
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a full-spectrum-converted camera the R, G, and B filters on the sensor array remain. These filters also differ in their transmittance for wavelengths in the UV-A and NIR regions, thus, in UV-A and NIR the R, G, and B channels in the sensor respond differently to different wavelengths, even in the absence of red, green and blue light. When the data are “interpreted” by the software (raw converter) as for visible light a false-colour image results. Depending on the case the false colour can be informative or a nuisance. If found a nuisance or confusing the image can be converted from <em>colour</em> into <em>greyscale</em> based on the three channels or by extracting the data for a single colour channel.</p>
</div>
</div>
<p>A camera converted to “full-spectrum” is usefully sensitive to an extended range of wavelengths of approximately 340 nm to 1000 nm. This range can be constrained by means of optical filters attached either in front or behind the lens. Thus, a “full-spectrum” converted camera can be used for UV-A, VIS or NIR photography by swapping filters. Having a camera sensitive to a wider range of wavelengths is only one requirement, an objective (= lens) that transmits and performs well in the UV and NIR regions is also needed.</p>
</section>
<section id="head-less-specialised-cameras" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="head-less-specialised-cameras"><span class="header-section-number">9.2.2</span> Head-less specialised cameras</h3>
<p>The cameras most frequently used for photography have a live-view screen or a viewfinder that makes framing and focusing possible. In contrast, machine vision cameras used in industrial automation and cameras for astronomy, microscopy and other scientific uses are designed to be used thetered to a computer (rarely to a tablet or smartphone), and in most cases lack a means to display images. Headless cameras lack or have minimalistic controls, they are designed to be controlled remotely. They can be thetered to a nearby computer using USB or similar connection, or to farther away devices through a LAN or the internet, and controlled of supervised either by a human operator or automatically bt software <a href="#fig-headless-camera" class="quarto-xref">Figure&nbsp;<span>9.2</span></a>.</p>
<p>These cameras are frequently called following computing jargon as being “headless” cameras.</p>
<div id="fig-headless-camera" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-headless-camera-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/GXVISION-OV9281-120fps-USB-Monochrome.png" class="img-fluid figure-img"></p>
<figcaption>GXVISION monochrome camera based on OMNIVISION’s OV9281 image sensor</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/Pi-camera-3.png" class="img-fluid figure-img"></p>
<figcaption>Rapsberry Pi camera 3 based on the Sony IMX708 sensor</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/Lucid-Triton-IP67.png" class="img-fluid figure-img"></p>
<figcaption>LUCID Triton Industrial machine vision camera</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/sCMOS-Excelitas.jpg" class="img-fluid figure-img"></p>
<figcaption>.pco PANDAS 26 USB microscopy camera</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-headless-camera-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.2: Two examples of very cheap headless cameras, and two examples of expensive cameras. A monochrome “machine vision” camera with global shutter and capable of 120 fps, but low resolution of 1 M pixel, from Gxvision (China) and of a Rapsberry Pi model 3 camera 11 M pixel. Both cameras are small and cost less than 50 €. LUCID’s Triton is a very small 20 MP camera capable of 5.5 fps in rugged metal case with IP67 ingress-protection rating available for about 500 €. Excelitas .pco PANDAS 26 USB camera has a 26 MP sensor and supports exposure times between <span class="math inline">27\,\mu s</span> and <span class="math inline">12\,s</span> with a global electronic shutter. It sells for approximately 10,000 €.
</figcaption>
</figure>
</div>
<p>Specialised digital cameras used in industrial automation (= “machine vision”), astronomy, microscopy, etc., frequently use the same or similar image sensors as photographic cameras, but unusual wavelength sensitivity ranges are more common. Monochrome head-less cameras are also more abundant than monochrome photographic cameras. Digital NIR cameras are common, i.e., sold as surveilance and “night-vision” cameras. Cameras for UV-A are rather common for especific uses, as many Si-based sensors are natively sensitive to it. Very few digital cameras designed for UV-B and even UV-C imaging are available, based on especialized sensors with an extended wavelength sensitivity range. One example is LUCID’s Atlas10 UV camera based on Sony’s IMX487 UV sensor, recomended for imaging in the range 200 to 400 nm. This new UV sensor produces 8 MP images at up 137 fps. At the other edge of the VIS band LUCID’s Atlas10 SWIR camera based on Sony’s IMX992 TE-cooled SWIR image sensor is usable for imaging in the range 400 nm to 1700 nm at 119 fps. These momochrome cameras although aimed at industrial inspection and garbage sorting cover wavelengths of special interest in plant photobiology research and close-range remote sensing.</p>
<p>While many headless cameras are intended to be mounted at a fixed position, others are suitable for use in drones. While industrial cameras are built for a harsh environemnt those for use in drones are smaller and lighter. In most cases these cameras produce live images, and can be fully controlled remotely. They are connected either “by wire” (ethernet or USB interfaces) or wirelessly (Wifi). Given that they are not used handheld but instead fixed and in many cases continuosly switched on, they in most cases lack an internal battery and depend on an external power source such as a mains adapter, power over ethernet, USB or external battery.</p>
<p>Being especialised some of these cameras have features not available in consumer or professional photographic cameras. They are in many cases available with sensor variants with or without NIR and/or UV blocking filters and in versions with colour or monochrome sensors. Recently Sony has announced an image sensor with sensitivity reaching UV-C and is likely to target industrial and scientific uses.</p>
<p>Some modern photographic cameras can capture bursts of images at frame rates of 200 fps. Some of the cameras used for machine vision and research are capable of capturing images at even faster rates (e.g., <span class="math inline">1\,000</span> or even <span class="math inline">1\times 10^6</span> fps). Other cameras, such as those used for astronomy, have sensors with a very low dark noise floor, usually with thermoelectric cooling, able to capture images at very low light levels using very long exposure times.</p>
<p>There is also a range of cheaper cameras sold for use with microcontrollers (MCB, e.g., Arduino UNO, or ESP32 boards) or single-board computers (SBC, e.g., Raspberry Pi). Some of these cameras are available in two versions with and without a NIR-blocking filter. There are different models available, some with very small sensors selling for as little as 15 € while others with sensors similar to those used in good smartphones available for close to 100 €. Some of these cameras support relatively high frame rates but have low resolution while others have higher resolution but lower frame rates. A few even have autofocus. These cameras are used thetered to a MCB or a SBC using interface protocols supported almost exclusively by such boards. The connection to the boards is wired and at very short distances. Remote and local access is through the controller board. The MCB plus camera can thus function as a bare bones headless camera.</p>
<p>More recently very small boards based on ESP32 microcontrollers have become available with built-in cameras and able to connect through wireless prococols like Wifi, Bluetooth and Matter. The image sensors used in these cheap cameras even if in some cases have high pixel resolution have small pixels (small light capture area), and even if they can work resonanbly well under good illumination, image quality under weak light is poorer than with more expensive cameras, but still useful. This is the realm of the internet of things (IoT) where rapid progress is taking place. For example, some cheap boards are based on microprocessors well suited for image analysis and pattern recognition using pre-trained AI models.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Films for infrared photography
</div>
</div>
<div class="callout-body-container callout-body">
<p>With the adoption of digital cameras, many types of photographic films have been discontinued. Films with extended NIR sensitivity were frequently used for aerial photography, both in grey scale and false-colour types. Only a couple of types of grayscale “IR”, really extended-red-sensitivity, film are still available (e.g., Ilford SFX 200). These films are sensitive up to <span class="math inline">\approx 730-770</span> nm depending on brand and type. Normal film types used for visible light are sensitive to UV-A to a larger or smaller extent while no special films for UV are available.</p>
</div>
</div>
</section>
<section id="spectral-and-hyperspectral-cameras" class="level3" data-number="9.2.3">
<h3 data-number="9.2.3" class="anchored" data-anchor-id="spectral-and-hyperspectral-cameras"><span class="header-section-number">9.2.3</span> Spectral and hyperspectral cameras</h3>
<p>Spectral cameras cover the VIS wavelength range with more than three “colour” channels, achieving better wavelength resolution and reducing or avoiding <em>metamerism</em>. These cameras acquire a spectrum for each pixel in the acquired image. Hyperspectral cameras frequently cover a wider range of wavelengths and have relatively high wavelength resolution. Multispectral cameras are sensitive to only a few specific narrow wavelength ranges. However, different manufacturres not necessarily use the same naming criteria. Most of the these cameras cover the VIS and/or NIR but very rarely UV.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Metamerism
</div>
</div>
<div class="callout-body-container callout-body">
<p>Metamerism is inherent to the extractiion of detailed colour information using few detectors with partly overlapping wavelength sensitivity ranges. It results for such systems, including human vision, being unable to distinguish between some combinations of wavelengths from pure monochromatic light. This is the basis of the trick that creates “yellow”, “purple” and many other colours in a monitor or TV set capable of emiting only red, green and blue light.</p>
</div>
</div>
<p>Different spectral cameras use different approaches for image acquisition. Based on this, two distinct types are recognizable: 1) scanning cameras and 2) snapshot cameras. Scanning cameras acquire images one row of pixels at a time, i.e., they usually have high wavelength resolution but are not suited for fast moving subjects. Snapshot cameras acquire data for all pixels within a small fraction of a second, have lower wavelength resolution and can be used to image faster moving subjects. Cameras from two large suppliers are mentioned below, only as examples.</p>
<p><a href="https://cubert-hyperspectral.com/en/">Cubert</a> specialises in <strong>snapshot spectral cameras</strong>, based on different implementations. The most advanced of their cameras use a light-field-based technology that allows both high spatial and high wavelength resolution (e.g., 410 x 410 pixels, 350–1000 nm, 164 wavelength bands, FWHM 10 nm, max 4 fps for the very small Cubert Ultrix X20).</p>
<p><a href="https://www.specim.com">Specim</a> specialises in <strong>line scan cameras</strong> <em>push broom</em> cameras. These cameras are available in VIS versions and different VNIR, NIR and IR versions, reaching even thermal radiation wavelengths. Modern line cameras are faster than previous models (e.g., 400-1000 nm, 224 wavelength bands, FWHM 5 nm, 1024 pixels / line, xxxx fps depends on settings, for the Specim FX10).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Spectral imaging with non-spectral cameras
</div>
</div>
<div class="callout-body-container callout-body">
<p>Photography captures light reflected by the objects being imaged. Spectral reflectance can be measured in two ways: 1) under white illumination with a sensor or film that discriminates among wavelengths of the reflected light, 2) under white illumination and multiple images each taken using a different band-pass optical filter, using a sensor or film sensitive to a wide range of wavelength without discriminating among them, or 3) by sequential illumination with light of different wavelengths and multiple monochrome images. The first approach is normally used in colour photography using optical filters on the sensor or in the film. The second approach in different variations was the basis of early methods of colour photography, persisting until the 1950’s. The third approach is not in widespread use, but used in at least one currently available “spectral” inaging system for plant phenotyping (RAYN Vision System Camera, <a href="https://rayn.ag/">Rayn Growing Systems</a>). This approach has been also shown to be applicable in the field at archeological sites to identify layers in the soil profile <span class="citation" data-cites="Stott2025">(<a href="references.html#ref-Stott2025" role="doc-biblioref">Stott et al. 2025</a>)</span>. As the approach can be easily and cheaply implemented using a normal camera or even a SBC together with a cheap dedicated camera it is a promising approach for in-place plant phenotyping in controlled environments.</p>
<p>On the other hand, digital photographic camera sensors have nowadays fast readout times, making the capture of fast sequences of images possible with this more expensive cameras. Techniques based on merging images to create a multichannel image cube, increase image resolution, increase the depth of the in-focus region or enhance image dynamic range could be potentially combined with illumination with light of different wavelengths. Photographs from a test using a seven-channels LED array are shown in <a href="#fig-spectral-photos" class="quarto-xref">Figure&nbsp;<span>9.3</span></a>.</p>
<div id="fig-spectral-photos" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spectral-photos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/spectral-frames-7chn-colour.jpg" class="img-fluid figure-img" data-group="spectral-pansies"></p>
<figcaption>Images, not edited</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/spectral-frames-7chn-balanced.jpg" class="img-fluid figure-img" data-group="spectral-pansies"></p>
<figcaption>Images, white balanced</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/spectral-frames-7chn-gray.jpg" class="img-fluid figure-img" data-group="spectral-pansies"></p>
<figcaption>Images, grey scale converted</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spectral-photos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.3: Images acquired with an OM-1 digital camera with the subjects illuminated with a six-colours plus white LED array, using each channel in turn as light source. See <a href="https://www.photo-spectrum.info/pages/illumination/spectral-imaging.html">on-line article for the details</a>.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="thermal-cameras" class="level3" data-number="9.2.4">
<h3 data-number="9.2.4" class="anchored" data-anchor-id="thermal-cameras"><span class="header-section-number">9.2.4</span> Thermal cameras</h3>
<p>Thermal IR cameras, designed for temperature measurements are monochromatic and sensitive to radiation in the range <span class="math inline">8\,\mu m</span> to <span class="math inline">14\,\mu m</span> (for <span class="math inline">-20^\circ\mathrm{C}</span> to <span class="math inline">1500^\circ\mathrm{C}</span>), <span class="math inline">0.85\,\mu m</span> to <span class="math inline">1.1\,\mu m</span> (for <span class="math inline">450^\circ\mathrm{C}</span> to <span class="math inline">1800^\circ\mathrm{C}</span>, used for hot metal), and variations. As with other cameras, both thermal cameras with a built-in display and headless ones are available. There are available even miniature thermal cameras designed to be attached to smart phones.</p>
<div id="fig-thermal-cameras" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-thermal-cameras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/.png" class="img-fluid figure-img"></p>
<figcaption>Thermal image as grey scale</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-thermal-cameras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.4
</figcaption>
</figure>
</div>
<p>In the case of these cameras, no wavelength information is captured, only the emitted NIR radiation flux. This energy flux is converted into an estimate of surface temperature based on the known or assumed emittance of the objects in the image. Data are temperatures, one for each pixel. When false colours are used, they represent different temperatures.</p>
<div id="fig-thermal-image" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-thermal-image-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/thermal-faba-at-night-gray.jpg" class="img-fluid figure-img" data-group="thermal-faba"></p>
<figcaption>Thermal image as grey scale</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="temporary-images/thermal-faba-at-night-colour.jpg" class="img-fluid figure-img" data-group="thermal-faba"></p>
<figcaption>Thermal image as false colour</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-thermal-image-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.5: Thermal image of <em>Vicia faba</em> plants of two different genotypes differing in stomatal conductace. Leaves of plants on the left, seen darker or blue, are at near 20 C and those on the right, seen lighter or green, are at near 22 C. The pots and boxes, seen almost white or red, are at more than 25 C.
</figcaption>
</figure>
</div>
<p>When using a thermal camera it is important to be aware that objects that look transparent to us, like a glass window, are in most cases opaque to NIR. A thermal image of a window, will show its temperature, not of what is behind it. Given the very high NIR reflectance of aluminium if we point the camera at an aluminium sheet, the image will show like on a mirror, the image of the camera and the operator! The temperature recorded by the camera will better reflect our own and the camera’s temperature than the temperature of the aluminium sheet.</p>
<p>As glass is not transparent to NIR wavelengths sensed by thermal cameras, lenses and NIR windows are made of other materials, such a Germanium.</p>
</section>
</section>
<section id="objectives" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="objectives"><span class="header-section-number">9.3</span> Objectives</h2>
<section id="photography-objectives" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="photography-objectives"><span class="header-section-number">9.3.1</span> Photography objectives</h3>
<p>The focal length of an objective determines the size of the projected image. Camera lenses with a fixed focal lens are called “prime lenses” and lenses with a variable focal lenght are called “zoom lenses”. A <em>normal</em> focal length is one that approximates the field of view of human vision (ignoring periferical vision). For a rectagular “frame” this corresponds to an angle of view of approximately <span class="math inline">45^\circ</span> measured on its diagonal. Film sizes as well as digital sensor sizes as well as their aspect ratio vary. Thus, the “normal” focal length depends on the film or sensor size of the camera. Camera lenses with shorter focal length than “normal” provide a broader field of view and are called “wide angle lenses”. Those with focal length longer than “normal” are called “tele objectives”. “Tele-converters” are lenses that modify the focal length of other lenses by increasing it. The less common “speed boosters” change the effective focal length in the opposite direction, widening the field of view, and consequently increasing the photon flux reaching the sensor or film.</p>
<p>Lenses designed for different sensor or film sizes project images of a size that roughly matches them. The diameter of the “image circle” that lenses project at the plane of the film or sensor usually only slightly exceeds the length of the diagonal of the sensor or film frame. This is in large part driven by the desire to keep lenses light in weight and small in size. Additionally, a smaller area unecesarily illuminated outside the sensor or film, fewer problems with light reflections inside the camera.</p>
<p>“Speed-booster” auxiliary lenses can be used only together with lenses having an image circle larger than necesary for the sensor in use, i.e., designed for a larger sensor or film size than the one being used.</p>
<p>In addition to angle of view, focusing distance determines magnification. Modern general-purpose camera lenses tend to perform very well from far to close distances, and in general have the minmum focusing distance nearer than “classical” lens designs from half a century or longer ago. Special lenses for macro photography remain relevant, as the magnification they achieve at their closest focusing range has also increased compared to that achieved with older designs. One extreme case is the M.Zuiko 90 mm f3.5 Macro lens from OM-System (formerly Olympus) that at its highest magnification the whole sensor image corresponds to <span class="math inline">4 \times 3\,\mathrm{mm}</span> on the photographed subject. This objective performs flawlessly from this closest focusing distance all the way to infinity focus.</p>
<p>Modern camera lenses use (very) complex designs, and because of this, they sometimes seem to disobey the laws of optics. Many profesional lenses have internal focusing mechanisms that displace only some optical elements, while in classical lens designs focusing was achieved by changing the distance between the lens as a whole and the film. One reason for the adoption of internal focusing is the widespread reliance on auto-focus. Reducing the mass of glass that needs to move alows faster focusing using less energy, two crucial goals in modern lens design. Some lenses have multiple optical groups that move relative to other when focusing or zooming.</p>
<p>Most modern lenses are sharp enough for most uses, even those aimed at “consumers” rather than “professionals”, or even many, but not all, medium priced Chinese lenses. Things that can be better in professional lenses are: faster auto-focus, wider maximum apertures (“faster lenses”), image stabilization, weather-sealing, rugged construction, smoother-looking out-of-focus areas (= better bokeeh), and to some extent better control of in-lens reflections. Generally, profesional lenses are easier to use or perform better in extreme or difficult situations and are designed to withstand more intense use. For example <em>some</em> professional cameras and lenses can be safely used in heavy rain or under low freezing temperatures without any special protection. From a user perspective, profesional lenses tend to maintain a proportionaly higher resale value for a longer time that cheap consumer lenses. This relates to both their sturdier build, lower availabilty and depending on brand, also easy of repair.</p>
</section>
<section id="objectives-for-uv-and-nir-photography" class="level3" data-number="9.3.2">
<h3 data-number="9.3.2" class="anchored" data-anchor-id="objectives-for-uv-and-nir-photography"><span class="header-section-number">9.3.2</span> Objectives for UV and NIR photography</h3>
<p>For an objective to be suitable for UV or NIR photography it has to have reasonably high transmittance of the wavelengths to be captured in the image and it has to be <em>corrected</em> for image aberrations and other problems at these same wavelengths. There exist very few camera objectives that can transmit and are corrected for UV-A, UV-B and even UV-C, and those that exist are extremely expensive (<span class="math inline">&gt; 10\,000</span> €) and fragile. I will not discuss such objectives further, as I never had access to one. Instead, I will discuss the cheaper alternative of using normal objectives. Three main difficulties are usually encountered when attempting to use normal objectives: transmittance limited to UV-A1 and longer wavelengths, ghosting and haze, and optical aberrations than can decrease image resolution and/or decrease contrast.</p>
<p>Most modern, and many vintage, objectives have very low transmittance in the UV region. In addition to the cut-in wavelength, the shape of the transmission spectrum varies depending on the lens. The reason for this is in the glass used, its thickness, the cemment used to assemble lens groups and the properties of the antireflection coatings applied. A general “wisdom” not free of exceptions is that the more elements (more surfaces with coatings) and the thicker these glass elements are, the less likely an objective is to have good UV transmission. This usually means that simpler designs and slower (smaller maximum apperture) objective are more <em>likely</em> to transmit some UV-A radiation.</p>
<p>In general, older or “vintage” objectives had simpler designs and less effective coatings and as a result more frequently objectives based on old designs have higher UV-A1 transmittance. The modern exceptions are a few inexpensive objectives, including some autofocus ones. In general, accidental UV objectives are “prime lenses” (fixed-focal-length objectives) not zooms or extreme wide-angle. It is usual to describe objectives that are not designed for use in UV, but happen to work reasonably well as <em>“accidental” UV-capable objectives</em>.</p>
<p>It is not enough for a lens to have good transmittance as internal reflections can deteriorate the quality of images. To prevent reflections non-glass internal surfaces inside the “barrel” of objectives and the edges of glass (or plastic) optical elements are painted or treated black. Coatings and surfaces that have very low reflectance in the VIS region not necessarily have the same property outside the VIS region. One rather extreme case is black-annodized aluminium which is highly reflective in the NIR region.</p>
<p>When using objectives designed for VIS photography for NIR, problems tend to be different than with UV. Most photography objectives have rather high transmittance in the relevant part of the NIR region (700 to 1100 nm). However, when used in NIR many photography lenses produce images with <em>hot spots</em> (usually near the center of the image) as a result of internal reflections. In most cases this problem is more noticeable at specific appertures. Ghosting caused by specular reflections within the lens is visible in images as bright spots with the shape of the diaphrogm apperture (the opening or “hole”). Flare, caused by scattered reflected light results is a decrease in image contrast. Although there are many more objectives suitable for NIR photography than for UV-A photography, it is important to keep in mind that some objectives produce better images than others.</p>
<p>Chromatic aberrations, which can affect UV, VIS and NIR, appear when the path of light of different wavelengths through a lens differs. For example, when a white object is photographed, the red, green and blue components can be slighly displaced from each other when projected on the sensor or film. In digital photographs chromatic aberretations are visible in high contrast edges as coloured halos. Most ordinary photography objectives are corrected for these aberrations by design only in the VIS range, thus, how objectives behave outside this range is an “accident”. Given the nature of these aberrations the narrower the range of wavelengths captured, the less likely it is that they will affect an image.</p>
<p>The design of any objective is a compromise among multiple goals reflected in design criteria, related not only to image quality, but also usability, size, weight and cost of manufacture. The design of different objectives is based on a different compromise. In spite of this, some objectives happen to work reasonably well outside the range of wavelengths for which their design was optimized. They never match the performance of objectives designed for UV photography, which can be used all the way to 250 nm or even shorter wavelengths. However, these extremely expensive and fragile objectives are overkill when the sensor of a camera is only sensitive to <span class="math inline">\lambda &gt; 330\ldots350</span> nm.</p>
<p>Finding a good accidental UV objective is made easier by lists published on the internet. Similar lists exist for objectives that are free of hot-spot problems. These lists are in many cases based on informal tests using different criteria and methods depending on the contributor of the data. They serve mainly as an indication, but provide no guarantee. In addition, many now vintage lenses were manufactured during several decades, with occasional changes in antireflection coatings or other alterations to their design that can affect UV transmittance. There are a couple of modern objects, available new until a few years ago, that do transmit UV-A1, support autoexposure, and with strong illumination even autofocus in UV-A1.</p>
<p>In the case of hot spots under NIR, the assessments on which the lists are based are even more subjective than for UV as they are usually based on visual assessment of images. As hot spots are reflections they are highly dependent on the position of light sources. How visible or disturbing they are depends on the subject matter photographed as they are more disturbing on dark than on bright images. In the case of NIR, many modern as well as old objectives can be used at least at some appertures.</p>
<p>When using vintage objectives on modern cameras one needs to rely on adapter rings, and when using non-macro objectives for macro photography, extenssion tubes have to be inserted between the objective and the camera. Quite frequenty one can find statements that such tubes without any glass cannot degrade image quality. This is far from true, and frequently a problem, especially for NIR photography. Many cheap adapters and extension tubes are made of aluminium made black by anodization and are internally highly reflective to NIR radiation. Even if black, they can be shiny enough to also degrade image quality in VIS light. It is common that in good quality adapters and extension tubes, as well as in objectives, the inside is ribbed perpendiculalry to the axis of the objective. The ribbing helps control especular reflections, and when combined with a non-reflecting black paint, is very effective. If the ribbed surface is reflective, light is scattered and glare affects the image. It is possible to paint the interior wall of extension tubes and adapters oneself if the manufacturer has not done so. The choice of paint is important as only some special paints absorb 95% or more of NIR and UV. That a paint is black in the VIS region gives no guarantee of it being UV and/or NIR “black”.</p>
<p>Reflections are not the only problems low quality adapters and tubes can introduce. If the dimensions of the mounts and especially the length of adapters is wrong, focusing at infinity can become impossible and the distance markings on focusing rings biased. This effect is most noticeable with wide angle objectives, e.g., for a fisheye objective with a focal length of 4.5 mm, the required accuracy in the adapter is a very small fraction of a millimetre. It is important to be aware of these possible problems. If the adapters are too short adding shims to slightly raise the lens-side mount of the adapter is possible in some cases. A shim is a usually a think metal sheet, in the case of lenses ring-shaped. For tube diameters used in telescopes shims are readily available in thicknesses varying from 0.1 mm to 1 mm or more. Lacking metal shims, hard plastic can also be used.</p>
</section>
</section>
<section id="optical-filters" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="optical-filters"><span class="header-section-number">9.4</span> Optical filters</h2>
<p>Optical filters select wavelengths through absortion and/or through reflection. Each type has its limitations and benefits, both in performance and cost. How good a filter is needed depends on multiple factors, including illumination spectrum and irradiance compared to the strength of the radiation captured in the image. As fluorescence of plants has in geenral a rather low quantum yield, photographying fluorescence requires filters that block out-of-band radiation extremely well (<span class="math inline">\approx \mathrm{OD} &gt;= 5</span>, or <span class="math inline">T &lt;= 0.00001</span>). UV-A photography in sunlight is not so challenging, but still many filters do not block NIR or VIS well enough (<span class="math inline">\approx \mathrm{OD} &gt; 3</span>, or <span class="math inline">T &lt; 0.001</span>, is usually recommended).</p>
<p><strong>Absorptive glass filters</strong> are based on “ionic” glass, i.e., glasses including different ions in their composition. Some of the ions tradditionaly used are metals like iron, lead, copper and chrome. As with any material absorbing photons, fluorescence is one of the possible energy dissipation mechanisms. Thus, some of these filters, e.g., when illuminated with UV-A radiation emit fluorescence in the visible range, and others emit NIR fluorescence when illuminated with blue light. The absorptance depends on their thickness as the glass as a whole has uniform properties across its depth. The change in the absorptance spectrum with the angle of light incidence is moderate. Their cut-offs and cut-ins are gradual, and these filters are available as band-pass, short-pass and long-pass filters (<a href="#fig-img-filters-ionic" class="quarto-xref">Figure&nbsp;<span>9.6</span></a>). From the perspective of their use, as the transmitted bands are broad, the distinction between short-pass and band-pass gets blured, i.e., most UV-A and UV-B “short-pass” filters are really band-pass filters as they do block UV-C wavelengths. Ionic-glass are not good enough for fluorescence or UV imaging, but work well for refelcted NIR photography. One exception to this rule is that very thick glass filters can have high out-of-band absorptance with not to low in-band transmittance (e.g., TSN340 from Tangsinuo is a glass filter about 10 mm-thick).</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">convertTfrType</span>(filters.mspct[<span class="fu">c</span>(<span class="st">"Schott_RG695"</span>, <span class="st">"Schott_UG1"</span>)],</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">facets =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-img-filters-ionic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-img-filters-ionic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-img-filters-ionic-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-img-filters-ionic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.6: Total transmittance spectra of two absoptive ionic filters. A short-pass UV filter (UG1 fron Schott) and a long-pass NIR filter (RG695, from Schott).
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Filters can deteriorate
</div>
</div>
<div class="callout-body-container callout-body">
<p>Some types of ionic glass filters have high concentrations of metal salts in their composition and their surface can oxidise in contact with humid air. If they have antireflection, or other coatings or thin layers deposited on their surface they tend be well protected. Those, with no coatings, can need especially in wet climates to be polished using fine cerium oxide paste or restored chemically. The recommendation is to store filters in a dry place and to regularly inspect the condition of their surface.</p>
<p>The spectral transmittance of both clear plastic and glass can change on exposure to strong light, specially blue and shorter wavelengths. In the case of plastics, not only cellulose acetate is affected. Of glasses, those containing iron, usually as an impurity, are the most prone to “yellowing” through “solarization”.</p>
<p>Scratches on the coatings or the glass surface, if small and superficial, tend to affect image quality mainly through reflections generating haze and sometimes small ghosts. Small scratches themselves are in most situations completely out of focus and invisible. The wider the aperture, the less likely they are to show in the images.</p>
</div>
</div>
<p><strong>Plastic filters</strong> are sometimes used for photography, specially at relatively large sizes like <span class="math inline">50 \times 50</span> mm or <span class="math inline">100 \times 100</span> mm squares 2 or 3 mm-thick, as they are cheaper than glass. They can be easily damaged in ways that can affect the quality of images, and need to be handled carefully. On the other hand, small scratches are irrelevant when filters are used on light sources, but in this case it is necessary to protect them from excessive heat. On light sources of many kinds it is common to use coloured plastic films or “theatrical gels” rather than thicker materials.</p>
<p>Until approximately 50 years ago <strong>gelatine filters</strong> were common. Obviously a thin layer of dry coloured gelatine is extremely fragile, but because they are so thin affect an optical system much less than thicker filters. They are still used, especially for filters located between the back of a lens and the sensor or film. When a thicker glass filter is located between sensor or film and objective, the focus point shifts, in extreme cases restricting the focusing range of the objective.</p>
<p>There is an additional type of absorptive filters, formely very common in photography: a thin light-absorbing layer of coloured <strong>gelatine encased between two layers of optical glass</strong>. As far as I know, only <a href="https://tiffen.com">Tiffen</a> still makes filters of this kind (<a href="#fig-img-filters-tiffen-haze" class="quarto-xref">Figure&nbsp;<span>9.7</span></a>).</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">convertTfrType</span>(filters.mspct<span class="sc">$</span>Tiffen_Haze_2A_2<span class="fl">.6</span>mm_52mm,</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-img-filters-tiffen-haze" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-img-filters-tiffen-haze-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-img-filters-tiffen-haze-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-img-filters-tiffen-haze-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.7: Total transmittance spectra of a filter made as an film encased between two glass layers. A UV-blocking filter, or “haze” filter (type 2A from Tiffen).<br>

</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Interference filters</strong> work by reflection from surface multilayer thin coatings. As with reflection in general, reflectance by the thin layers is affected by the light incidence angle. In this type of filters the cut-off and cut-in wavelengths shift significantly at shallow light incidence angles compared to normal incidence. Their main advantage is that they can be designed to have very sharp cut-in and cut-offs, can have multiple discontinuous trtansmission bands and very strong blocking of off-band radiation (<a href="#fig-img-filters-uvcut-interference" class="quarto-xref">Figure&nbsp;<span>9.8</span></a>). They are available with transmitted bands as narrow as a couple of nm to 100’s of nanometres. However, only the best and most expensive interference filters achieve such high performance. The better filters have more thin-layers with more accurate thickness, which increases the fabrication cost. As they are usually deposited on optical-grade quartz as subtrate, the thikness of the substrate of these filters has little if any effect on their spectral properties. The thin films are fragile, so some of these filters have a hard-coating added at their surface for protection. In spite of working by reflection, which face of the filter points to the light source does not significantly affect their spectral transmittance. Some of these filters have coatings on only one surface, while other can have different coatings on their two surfaces. It is important to remember here that reflections take place at each interface between media of different refractive indexes.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">convertTfrType</span>(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>      filters.mspct[<span class="fu">c</span>(<span class="st">"Zeiss_UV_Tstar_2.0mm_52mm"</span>, </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Firecrest_UVIR_Cut_0.96mm_52mm"</span>)],</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">facets =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-img-filters-uvcut-interference" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-img-filters-uvcut-interference-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-img-filters-uvcut-interference-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-img-filters-uvcut-interference-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.8: Total transmittance spectra of two dichroic or interference filters, one UV-blocking (Zeiss UV T*) and one UV and IR-blocking (Firecrest UVIR cut). Both filters are in addition antireflection multicoated.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Some of the best VIS-blocking UV-pass filters for photography and astronomy (“Venus filters”) are interference filters with VIS-absorbing ionic glass as substrate. Some of them, even have different interference filters deposited on each of their faces. The added interference filter coatings blocks the IR “leaks” that the ionic glass has (<a href="#fig-img-filters-uv-pass" class="quarto-xref">Figure&nbsp;<span>9.9</span></a>). Some photographers argue that which face of these filters faces the sensor can affect reflections within the camera resulting slightly different amounts of glare. Of the ordinary filters used in VIS photography, only some UV-blocking filters, some neutral density filters and all UV + NIR blocking filters are interference filters, most other filters are absprptive.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">convertTfrType</span>(</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>      filters.mspct[<span class="fu">c</span>(<span class="st">"Baader_U_filter_1.0mm_48mm"</span>, </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Schott_UG11"</span>)],</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">facets =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-img-filters-uv-pass" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-img-filters-uv-pass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-img-filters-uv-pass-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-img-filters-uv-pass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.9: Total transmittance spectra of two short-pass UV filters, one an dichroic or interference filters on a 1 mm-thick Schott UG11 ionic glass substrate (Bader Venus-U), and the other a plain 2 mm-thick UG11 ionic glass filter (Firecrest UVIR cut). Both filters are in addition antireflection multicoated.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Each glass-air interface reflects approximately 4.5% of the light traversing it as result of the difference in refractive index (<span class="math inline">n</span>). Modern lenses and good photographic filters are <strong>anti-reflection multicoated</strong>, and the best ones reflect <span class="math inline">&lt; 0.1\%</span> of the light impinging on their surface. These coatings are similar in principle to interference filters, they change <span class="math inline">n</span> at the surface. However, they are designed to minimize reflections across a given range of wavelengths instead of increeasing them. In recent years a further additional coating is being applied to outer lens surfaces and filters, a fluorine compound coating that alters surface properties so that water runs off the surface and dirt does not stick. Antireflection coatings do modify the spectral transmittance, increasing it in the target range of wavelengths but frequently decreasing it in other regions of the spectrum.</p>
</section>
<section id="uv-vis-and-nir-radiation-sources" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="uv-vis-and-nir-radiation-sources"><span class="header-section-number">9.5</span> UV, VIS and NIR radiation sources</h2>
<p>As in many applications, LEDs have replaced incandescent lamps as light sources for VIS photography, while Xenon-arc flashes remain popular. The spectrum of white light sources based on LEDs used in photography has improved in recent years. The suitability of white LED light is rated based on indexes, of which the most frequently reported is the colour rendition index (CRI), expressed in a scale from 0 to 100. In practice, good colour reproduction in photographs requires CRI &gt;= 95 (<a href="#fig-imge-white-leds-cri" class="quarto-xref">Figure&nbsp;<span>9.10</span></a>). Most white LEDs used in households, public spaces and growth chambers have CRI &lt;&lt; 90 and sometimes CRI &lt; 80. This should be taken into consideration when photographs are used to record the outcome of experiemnts.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(leds.mspct[<span class="fu">c</span>(<span class="st">"SeoulSemicon_S4SM_1564509736_0B500H3S_00001"</span>,</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Nichia_NFCWL036B_V3_Rfcb0"</span>, </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"Nichia_unknown_757"</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"Luminus_CXM_14_HS_12_36_AC30"</span>)],</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">facets =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-imge-white-leds-cri" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-imge-white-leds-cri-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-imge-white-leds-cri-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-imge-white-leds-cri-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.10: Emission spectra of four white LED of different types, two with high CRI (Sunlike, from Seoul Semicon and Optisolis from Nichia) and two with lower CRI (an older Nichia LED and a modern LED for horticulture from Luminus).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Daylight is a good source of UV-A1 radiation during most of the day. When the sun is more than 30 or 40 degrees above the horizon UV-A1, UV-A2 and UV-B are usualy enough for photograpying still subjects. The irradiance of NIR compared to VIS in daylight varies less than that of UV-B and UV-A. As described in Chapter XX, the scattering of sunlight in the atmosphere is more at shorter than at longer wavelengths. Lanscapes look very different in a UV and in a NIR image. The proportion of UV-A in the shade can be high but the low irradiance makes very long exposures necessary. When using “accidental” UV objectives their rather low transmittance compounded with a decreased sensor sensitivity at short wavelength usually makes UV photography in natural light challenging because of long exposure times.</p>
<p>Xenon flash lamps emit as much or more UV-A radiation than VIS light, but those sold for VIS photography are in most cases filtered so as to block all UV to make their use safer and to avoid a blue cast in photographs. A Xenon flash arc inherently emits across the whole UV-A, UV-B and UV-C, VIS, and NIR regions. However, depending on the glass or quartz lamp envelope, the shorter wavelengths may not exit the lamp. However, even Xenon flash lamps with a glass envelope emit UV-A radiation. The spectrum even if full of features (peaks and valleys), is rather continuous (<a href="#fig-img-xe-flash" class="quarto-xref">Figure&nbsp;<span>9.11</span></a>).</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(lamps.mspct[<span class="fu">c</span>(<span class="st">"Godox.XeF.AD200.H200j.FTSTS40w.flash"</span>, </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"Godox.XeF.AD200.H200.flash"</span>)],</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">facets =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-img-xe-flash" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-img-xe-flash-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-img-xe-flash-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-img-xe-flash-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.11: Emission spectra of two different “heads” on the same Xenon flash (Godox AD200) one original and filtered to block all UV radiation and one with quartz flash tube, not filtered, from a different supplier (FTSTS40W quartz Xenon lamp on a Godox H200j bare-lamp flash head).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Radiation from Xenon flashes, similarly to sunlight, can produce false-colour UV and NIR images. This is true, even if filtered to block UV-B and UV-C for safety. UV-B and UV-C wavelengths are blocked by “accidental” UV objectives and anyway not detected by digital sensors even in full-spectrum modified cameras.</p>
<p>LEDs with peaks of emission between 365 nm and 415 nm do emit UV-A1 and are cheap and readily available. However, because of their rather narrow peaks of emission (<a href="#fig-img-leds-uva" class="quarto-xref">Figure&nbsp;<span>9.12</span></a>) they create nearly monochromatic images, with little false colour, when used singly. One possibility is to use an array with a mix of LEDs emitting at different but partly overlapping UV-A wavelengths.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(leds.mspct[<span class="fu">c</span>(<span class="st">"LedEngin_LZ1_10UV00_365nm"</span>,</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"LedEngin_LZ1_10UB00_00U4_385nm"</span>)],</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">facets =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div id="fig-img-leds-uva" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-img-leds-uva-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imaging_files/figure-html/fig-img-leds-uva-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-img-leds-uva-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.12: Emission spectra of two 4W UV-A1 LEDs (types LZ1-10UV00 and LZ1-10UB00-00U4 from Led Engin-Osram).
</figcaption>
</figure>
</div>
</div>
</div>
<p>In the case of NIR all three sources are effective: sunlight, Xenon flash and LEDs. This is helped by the high native sensitivity of Si-based image sensors in this region of the spectrum. LEDs with their narrow peaks of emission unless combined, fail to produce strong false colour effects. Because of the properties of the red, green and blue filters on pixels of camera sensors, the false colour originates mostly from R and FR wavelengths <span class="math inline">\lambda &lt; 850 \mathrm{nm}</span>.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>Illumination flicker
</div>
</div>
<div class="callout-body-container callout-body">
<p>Many light sources including all incandescent lamps and many gas-discharge- and LED lamps, flicker at twice the frequency of the AC power line. The AC line frequency, 50 Hz or 60 Hz, has most likely been chosen so that the light fkicker is not noticeable to human vision. Modern electronic ballasts for gas-discharge lamps and drivers for LEDs tend to use higher frequencies, anywhere between 300 Hz and a few kHz. However, two contrasting approaches to LED dimming are in use. Some LED drivers use a constant-current approach to dimming, and avoid flicker completly. Meanwhile other drivers use the pulse-width-modulation approach (PWM) to dimming, that consist in switching the LEDs on and off at a usually fast frequency. Old-style mains dimmers generate strong flicker at line frequency.</p>
<p>Flicker and the more drastic PWM dimming need to be taken into account when selecting the shutter speed used. At fast shutter speeds (= short exposure times), both in film and in most digital cameras, there is a small difference in time when different parts of an image are acquired. Under light flickering in brightness, banding in images apears as subtke differences in exposure. In the case of PWM diming banding can is some cases apears as black unexposed bands. In the case of colour-mixing LEDs based on PWM the bands can be of multiple colors.</p>
<p>The general solution to this problem is to use a suficiently long exposure time, and when possible ensure that the exposure time is such that includes a whole number of flicker cycles. When flicker is synchronized to the AC power line frequency, the frequency is known and the exposure time can be selected accordingly. For example, in Europe this frequency is 50 Hz and the flicker frequency 100 Hz, so using an exposure time of 1/50 s is preferable to using 1/60 s. With modern LED drivers there is no known frequency, and even the frequency and phase of the flicker from different luminaires can differ. Unless the camera being used can detect the frequncy and automatically tweak exposure times, the good and bad exposure times can be learnt by trial an error. There is a further possibility, if the sensor readout time is known, the frequency of the flicker can be estimated from the banding recorded in an image.</p>
<p>LED light sources sold for photography and video, in general use CC dimming or alternatively PWM dimming at a high frequency. The flicker in the later is noticeable only in images acquired using very fast shutter speeds.</p>
</div>
</div>
</section>
<section id="accessories" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="accessories"><span class="header-section-number">9.6</span> Accessories</h2>
<section id="colour-and-grey-scale-references" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="colour-and-grey-scale-references"><span class="header-section-number">9.6.1</span> Colour and grey-scale references</h3>
<p>White, black and grey references have two main uses. One is to optimally and consistently set exposure independently of the reflectance of the subject of the photograph. The second, and more familiar use, is to set the white balance on a light grey or white reference, so that it describes the light source idependently of the subject photographed. If included in images, white balance can be adjusted objectively also in post-processing. With set of grey patches it becomes feasible, although not easy, to compensate differences in in-camera exposure in post-processing. Although, a single grey reference of 18% reflectance helps in the overall adjustments of exposure, it does not provide enough information to compensate for differences in the steepness of the response curve and dynamic range among images. These properties images are affected by exposure and ISO settings.</p>
<p>Colour “checkers” with tiles of different colours with known spectral reflectance are routinely used in photography that requires faithful colour reproduction, e.g., commercial photography. They are available with different numbers of tiles, the more tiles the more colours that can be calibrated and corrected. The most comon colour checkers have 24 tiles, xx colours plus a gradation greys from white to black. They come in different sizes, small ones suitable for macro photography and several larger sizes. These easily available references cover only visible colours, i.e., those recorded by “normal” cameras. There exist reference tiles for UV and NIR, but they are extremely expensive.</p>
<p>The best approach is to use them to generate a custom colour profile for a given combination of light source, camera, objective and filter. However, the “colour cast” introduced by objectives and UV-cut or UVIR-cut filters is usually rather small.</p>
<p>A colour profile is constructed by photographying the colour target and loading the resulting image into software that analyses it and compares the pixel values to those expected for each tile. The procedure optimizes the multiplers to apply to the the R, G and B raw values from the camera sensor to convert them as close as possible to the expected values for each colour tile. The procedure also makes use of the black, white and grey tiles to adjust the response to luminosity. Some RAW file converters also support the creating of colour profiles. There are also computer programs for the construction of colour profiles.</p>
<p>The calibration procedure needed to obtain “true” colours consistently through time or across sites depends on colour references with accurately known spectral properties that are of high quality and have been recently acquired (because they age). In such a case we can assume that different colour targets from the same manufacturer and type are nearly identical and comparable. However, if we only aim to achieve good colour consistency across a single set of images together with imperfect but reasonably good colour reproduction, it is enough to use the same colour target as reference for all the images to be compared. Thus an older colour target or one with weaker specifications can reduce the expenses.</p>
<p>In general, the lower the CRI rating of a light source, the more necessary it is to use a custom colour profile. When assessing illumination, reflected light must be considered. For example, a LED lamp with very high CRI rating is used in a room with walls painted in a bright colour, the spectrum of the light effectively illuminating the object photographed most likely will differ in its spectrum from that emitted by the lamp.</p>
<p>Of all situations, the most challenging is when the light illuminating different parts of the object photographed differs in colour (= spectrum). Lamps used in household and commercial illumination have in most cases CRI &lt;= 85, and are also available with different colour-temperature ratings. Quite frequently, lamps that have been installed at different times differ in emission spectra, even within a given colour temperature and lamp brand. An more dramatic case is a mix of warmer artificial light and cooler daylight entering through windows. Whenever possible, strive to acquire images under light with a homogenous spectrum.</p>
</section>
</section>
<section id="procedures" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="procedures"><span class="header-section-number">9.7</span> Procedures</h2>
<section id="reproducibility" class="level3" data-number="9.7.1">
<h3 data-number="9.7.1" class="anchored" data-anchor-id="reproducibility"><span class="header-section-number">9.7.1</span> Reproducibility</h3>
<p>When used in research, imaging can be done for illustration purposes or as an approach to quantitative measurement. In the second case, reproducibility plays a crucial role towards correct quantification, while in the first case it is important to avoid misleading the viewers of the illustrations. In some fields, illustrative photographs are used as scientific evidence, thus, avoiding bias is also crucial even no quantification is done. Bias can be introduced both when the image is captured and during image post-processing.</p>
<p>Comparable images can be obtained by keeping illumination, image acquisition and post-processing perfectly consistent. When there is relatively small variation in illumination or camera response, the use of colour and grey references can allow corrections to partly remove bias. References within images can also serve as a built-in quality control. When the colours need to closely match the object photographed the use of “a colour managed workflow” is required. In such a workflow colur calibrations are used at each stage, and at each step loss of information is avoided. For example, a white light source deficient in violet or green light makes correctly recording those colours impossible. It is important to remember that digital photographics cameras, do not sense colours as narrow wavelength bands, but instead reconstruct the colours we see, discarding a lot of information. This makes the colour bias caused by illumination with a low CRI light source difficult to fully correct after the fact.</p>
<p>Most digital cameras set exposure automatically. However, when consistency is important, exposure must be set using a grey reference card (18% reflectance) either manually or the automatically found setting locked. Otherwise, the auto-exposure algorithm will compensate at least in part for the differences in luminance between objects, for example small vs.&nbsp;large plants on a dark or light background, or between dark and pale plants. If we are only interested in the shape of the plants, size, etc., some amount of bias can be tolerated. In contrast if reflectance or spectral reflectance (darkness or colour) are relevant, consistent exposure is crucial.</p>
</section>
<section id="uv-photography" class="level3" data-number="9.7.2">
<h3 data-number="9.7.2" class="anchored" data-anchor-id="uv-photography"><span class="header-section-number">9.7.2</span> UV photography</h3>
</section>
<section id="nir-photography" class="level3" data-number="9.7.3">
<h3 data-number="9.7.3" class="anchored" data-anchor-id="nir-photography"><span class="header-section-number">9.7.3</span> NIR photography</h3>
</section>
<section id="uvivf" class="level3" data-number="9.7.4">
<h3 data-number="9.7.4" class="anchored" data-anchor-id="uvivf"><span class="header-section-number">9.7.4</span> UVIVF</h3>
<ul>
<li><p>Camera: It is best to use a digital mirrorless (ML) camera. An off-the-shelf camera is the best tool unless NIR fluorescence is of interest.</p></li>
<li><p>Objective: Most lenses work well but given the very low light levels a lens with an f/2.8 apperture or wider is preferable.</p></li>
<li><p>Light source: A 365 nm LED-based flashlight works well if of enough power (&gt;= 3 W for a 0.25 m to 2.0 m range and static subjects), preferably with a Nichia LED and an VIS-blocking filter such as 3 mm or 2 mm-thick SWB2 filter. The induced fluorescence is weak so that if any visible light emitted by the UV source can go through both filters, it will show in the photographs.</p></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">smooth_spct</span>(lamps.mspct[<span class="fu">c</span>(<span class="st">"Convoy.S2plus.LED.UVA.flashlight"</span>)], </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method =</span> <span class="st">"supsmu"</span>, <span class="at">strength =</span> <span class="fl">0.001</span>),</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="imaging_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>On-camera filter: A high-quality UV-blocking filter is needed. Most UV-filters sold for photography have a cut-in at too short wavelengths (330 to 380 nm). However, when using a 365 nm LED as light source the filter used on the lens has to block wavelengths just past 400 nm. The best, but rather expensive, option is a Zeiss UV T* filter, second best is a significantly cheaper Firecrest UV400 filter (from Formatt-Hitech, apparently gone bankrupt), and a third option is a Tiffen Haze 2A filter (rather difficult to find outside USA). The first two are interference filters and reflect UV, rather than absorb it. The Tiffen filter, a rather old type in the tradition of Kodak Wratten filters, has a thin UV-absorbing gelatine layer encased between two glass sheets. None of these three filters fluoresce significantly when exposed to UV radiation. Most yellow, orange and red filters are made of ionic glass and when illuminated with UV fluoresce strongly. They can be used only behind a UV-absorbing filter. NIR pass filters are also ionic and do also fluoresce, but less intensively (I am not sure of which wavelengths induce the strongest fluorescence in NIR filters, but likely from the VIS range).</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(filters.mspct[<span class="fu">c</span>(<span class="st">"Zeiss_UV_Tstar_2.0mm_52mm"</span>,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Hoya_UV0_HMC_2.0mm_52mm"</span>)],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>)) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>) </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="imaging_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">autoplot</span>(<span class="fu">smooth_spct</span>(<span class="fu">normalise</span>(lamps.mspct[[<span class="st">"Convoy.S2plus.LED.UVA.flashlight"</span>]], <span class="at">norm =</span> <span class="st">"undo"</span>) <span class="sc">*</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                       filters.mspct[[<span class="st">"Zeiss_UV_Tstar_2.0mm_52mm"</span>]], <span class="at">method =</span> <span class="st">"supsmu"</span>, <span class="at">strength =</span> <span class="fl">0.5</span>),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="fl">6.2</span>), </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">annotations =</span> <span class="fu">c</span>(<span class="st">"-"</span>, <span class="st">"peaks"</span>)) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"Zeiss UV T* filter"</span>) <span class="sc">+</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)) <span class="sc">|</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>(<span class="fu">autoplot</span>(<span class="fu">smooth_spct</span>(<span class="fu">normalise</span>(lamps.mspct[[<span class="st">"Convoy.S2plus.LED.UVA.flashlight"</span>]], <span class="at">norm =</span> <span class="st">"undo"</span>) <span class="sc">*</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                       filters.mspct[[<span class="st">"Hoya_UV0_HMC_2.0mm_52mm"</span>]], <span class="at">method =</span> <span class="st">"supsmu"</span>, <span class="at">strength =</span> <span class="fl">0.5</span>),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="fl">6.2</span>), </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">annotations =</span> <span class="fu">c</span>(<span class="st">"-"</span>, <span class="st">"peaks"</span>)) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"Hoya UV(0) filter"</span>) <span class="sc">+</span> </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)) <span class="sc">+</span> <span class="fu">plot_layout</span>(<span class="at">axis_titles =</span> <span class="st">"collect"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="imaging_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-empty-content callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>UV-induced fluorescence of filters
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
<ul>
<li>Support: Exposure times between 20 s and a 2 min are common, so the camera must be mounted so that it cannot move. I normally use a tripod outdoors and a copy stand or a tripod indoors. Many modern camera can be controlled with a phone app, while older ones can be triggered with a cable or radio-remote. If a IR remote is to be used, better test that its light does not show in the photographs.</li>
<li>Location, outdoors: The best location is far from any artificial illumination in a moon-less night. How dark it needs to be depends on the length of expossure, so brightly fluorescing subjects like some lichens are more forgiving. At high latitudes, in the late spring and summer, it remains too bright through out the night. The autumun is the best season, especially if one gets a windless night.</li>
<li>Location, indoors: Even in a dark room, there are usually items that strongly fluoresce such as light-coloured clothing, white papers and even some plastics. One needs to move such items away and if not possible, set the UV-radiation beam to illuminate the subject but not those items.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Tools I use
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Camera: mirrorless digital cameras. Since three years ago Olympus OM-1, five years ago an Olympus E-M1 Mk II and about 10 years ago an Olympus E-M1. The OM-1 has a feature that is especially good for very long exposures: it can display the image while it is being captured, even on the screen of a phone or tablet. Used with the shutter in <em>bulb</em> mode one can close the shutter when the image looks bright enough. In addition, one can see live how light painting with the flashlight affects the image.</li>
<li>Objectives: I have used for many years most frequently a Sigma 30 mm f/1.4, and more recently an M.Zuiko 25 mm f/1.2 in its place. When needing other focal lengths the M.Zuiko 12-40 mm f/2.8 zoom has worked well. After all, one is just photographing VIS light, so almost any lens should work nicely optically.</li>
<li>On camera filter: the three mentioned above, interchangeably. Sometimes combined with long-pass filters.</li>
<li>Flashlight UVA: Convoy 2+ with 365 nm Nichia LED rated at 3 W. I replaced the clear window with a VIS-blocking filter. This flashlight has a narrow and very intense UV beam that works very well for light painting. Jaxman 1aC 365 nm 6W “flood” flashlight has a broader and less intense UV beam. It came already with a VIS-blocking filter installed. The two flashlight are physically very similar but differ in the LED and most significantly the reflector.</li>
<li>Flashlight, VIS: As I tend to take a paired reference photograph in white light for each fluorescence image, I use a 5W video fill light (SunwayFoto FL96). Many similar lamps are avaialble, but not all of them have a high colour rendition index (CRI). A value of 95 or higher is good for colour reproduction.</li>
<li>White reference slab: A normal colour chart is unsuitable. Some grey cards sold for white balancing can be used but I consider them too expensive to use in the field, especially in the dark. I use instead a piece a white “vigin” (not recycled) PTFE (=Teflon) about 6 mm thick. <em>Pure clean</em> PTFE has similar and very high reflectance in the UV, VIS and NIR, and can be easily washed to clean it.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>White balancing fluorescence photographs
</div>
</div>
<div class="callout-body-container callout-body">
<p>Objectively white balancing a photograph of fluorescence is nearly impossible. After trying other approaches I have mostly settled into editing the colour in these photographs to “look right”, i.e., matching my recollection of how the subject looked like when I photographed it. However, in some cases I use just a daylight balance and alternatively edit the colour to remove intense casts so as to increase the apparent colour range.</p>
</div>
</div>
</section>
</section>
<section id="further-reading" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">9.8</span> Further reading</h2>
<p>New books on digital photography techniques are regularly published, but few of them focus on the practice of photography rather than the principles and science behind. In my view, as in scientific photography consistency and reproducibility are a requirement, a deeper understanding is needed than for casual or even artistic photography. The book “Learning to Photograph” published in two volumes, even if slightly out-of-date, is my suggestion as a gentle but well informed introduction to digital photography <span class="citation" data-cites="Banek2013 Banek2013a">(<a href="references.html#ref-Banek2013" role="doc-biblioref">Banek and Banek 2013a</a>, <a href="references.html#ref-Banek2013a" role="doc-biblioref">2013b</a>)</span>. It was originally published in German <span class="citation" data-cites="Banek2012 Banek2012a">(<a href="references.html#ref-Banek2012" role="doc-biblioref">Banek and Banek 2012a</a>, <a href="references.html#ref-Banek2012a" role="doc-biblioref">2012b</a>)</span>.</p>
<p>The books by Alfred Blaker, although written before the digital photography times, provide technical information and practical advice still relevant to scientific photography <span class="citation" data-cites="Blaker1989">(<a href="references.html#ref-Blaker1989" role="doc-biblioref">Alfred A. Blaker 1989</a>)</span> and field photography <span class="citation" data-cites="Blaker1976">(<a href="references.html#ref-Blaker1976" role="doc-biblioref">Alfred A. Blaker 1976</a>)</span>. His book on depth-of-field was reprinted in 2026 <span class="citation" data-cites="Blaker1985">(<a href="references.html#ref-Blaker1985" role="doc-biblioref">A. A. Blaker 1985</a>)</span>. For French-speakers the book on macro-photography by Durand describes techniques comprehensively <span class="citation" data-cites="Durand1977">(<a href="references.html#ref-Durand1977" role="doc-biblioref">Durand 1977</a>)</span>.</p>
<p>Over the years Kodak has published and updated several technical handbooks, including about UV-B and NIR film photography <span class="citation" data-cites="Kodak1972">(e.g., <a href="references.html#ref-Kodak1972" role="doc-biblioref">Kodak 1972</a>)</span>. They focus heavily on the use of photographic films, but some of the information about filters remains of some use.</p>
<p>A more modern and very comprehensive account of photographic techniques used for scientific documentation, including UV, NIR and fluorescence imaging techniques was written by Enrico <span class="citation" data-cites="Savazzi2011">(<a href="references.html#ref-Savazzi2011" role="doc-biblioref">Savazzi 2011</a>)</span>. Two other comprehensive books were published in recent years <span class="citation" data-cites="Peres2017 Peres2021">(<a href="references.html#ref-Peres2017" role="doc-biblioref">Peres 2017</a>; <a href="references.html#ref-Peres2021" role="doc-biblioref">Peres 2021</a>)</span>. These three books cover a very broad set of techniques, and are best suited as reference or for studying scientific photography as a whole.</p>
<p>Easier to read, more narrowly focused books, on UV photography <span class="citation" data-cites="Prutchi2017">(<a href="references.html#ref-Prutchi2017" role="doc-biblioref">Prutchi 2017</a>)</span>, UV and NIR photography <span class="citation" data-cites="Davies2017">(<a href="references.html#ref-Davies2017" role="doc-biblioref">Davies 2017</a>)</span>, photographying plants <span class="citation" data-cites="Blacklock1990 Davies2023">(<a href="references.html#ref-Blacklock1990" role="doc-biblioref">Blacklock and Blacklock 1990</a>; <a href="references.html#ref-Davies2023" role="doc-biblioref">Davies 2023</a>)</span> and photographying the unseen <span class="citation" data-cites="Davies2020">(<a href="references.html#ref-Davies2020" role="doc-biblioref">Davies 2020</a>)</span> are possible the best for readers already familiar with basic photography techniques.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Banek2012" class="csl-entry" role="listitem">
Banek, Cora, and Georg Banek. 2012a. <em>Fotografieren Lernen: Bildgestaltung Und Bildsprache</em>. 1st ed. Vol. 2. Heidelberg: dpunkt.verlag.
</div>
<div id="ref-Banek2012a" class="csl-entry" role="listitem">
———. 2012b. <em>Fotografieren Lernen: Die Technischen Grundlagen</em>. Vol. 1. Heidelberg: dpunkt.verlag.
</div>
<div id="ref-Banek2013" class="csl-entry" role="listitem">
———. 2013a. <em>Learning to Photograph: Camera, Equipment, and Basic Photographic Techniques</em>. Vol. 1. Rocky Nook. <a href="http://www.ebook.de/de/product/20288815/cora_banek_georg_banek_learning_to_photograph_volume_1_camera_equipment_and_basic_photographic_techniques.html">http://www.ebook.de/de/product/20288815/cora_banek_georg_banek_learning_to_photograph_volume_1_camera_equipment_and_basic_photographic_techniques.html</a>.
</div>
<div id="ref-Banek2013a" class="csl-entry" role="listitem">
———. 2013b. <em>Learning to Photograph: Visual Concepts and Composition</em>. Vol. 2. Rocky Nook. <a href="http://www.ebook.de/de/product/20288816/cora_banek_georg_banek_learning_to_photograph.html">http://www.ebook.de/de/product/20288816/cora_banek_georg_banek_learning_to_photograph.html</a>.
</div>
<div id="ref-Blacklock1990" class="csl-entry" role="listitem">
Blacklock, Craig, and Nadine Blacklock. 1990. <em>Photographing Wildflowers: Techniques for the Advanced Amateur and Professional</em>. Stillwater, Minnesota: Voyageur Press.
</div>
<div id="ref-Blaker1985" class="csl-entry" role="listitem">
Blaker, A. A. 1985. <em>Applied Depth of Field</em>. 1st ed. Boston: Focal Press.
</div>
<div id="ref-Blaker1976" class="csl-entry" role="listitem">
Blaker, Alfred A. 1976. <em>Field Photography: Beginning and Advanced Techniques</em>. San Francisco: W. H. Freeman.
</div>
<div id="ref-Blaker1989" class="csl-entry" role="listitem">
———. 1989. <em>Handbook for Scientific Photography</em>. 2. ed. Boston [u.a.]: Focal Press.
</div>
<div id="ref-Davies2017" class="csl-entry" role="listitem">
Davies, Adrian. 2017. <em>Digital Ultraviolet and Infrared Photography</em>. Focal Press.
</div>
<div id="ref-Davies2020" class="csl-entry" role="listitem">
———. 2020. <em>Photographing the Unseen World: Art and Techniques</em>. La Vergne: Crowood.
</div>
<div id="ref-Davies2023" class="csl-entry" role="listitem">
———. 2023. <em>Plant Photography</em>. 1st ed. Photography Series. London: The Crowood Press.
</div>
<div id="ref-Durand1977" class="csl-entry" role="listitem">
Durand, A. 1977. <em>Photo Ciné Macro Graphie</em>. 4th ed. Paris: Publications Photo-Cinéma Paul Montel.
</div>
<div id="ref-Kodak1972" class="csl-entry" role="listitem">
Kodak, Eastman. 1972. <em>Infrared &amp; Ultraviolet Photography.</em> Kodak publication No M27/M28. Rochester: Eastman Kodak Company.
</div>
<div id="ref-Peres2017" class="csl-entry" role="listitem">
Peres, Michael R. 2017. <em>Laboratory Photography and Imaging: Best Practices for Photomicrography and More</em>. Edited by James Hayden, Ted Kinsman, and Staffan Larsson. Applications in Scientific Photography. New York: Routledge,.
</div>
<div id="ref-Peres2021" class="csl-entry" role="listitem">
———, ed. 2021. <em>NATURAL SCIENCE IMAGING AND PHOTOGRAPHY</em>. Applications in Scientific Photography. [Place of publication not identified]: Focal Press.
</div>
<div id="ref-Prutchi2017" class="csl-entry" role="listitem">
Prutchi, David. 2017. <em>Exploring Ultraviolet Photography</em>. Amherst Media.
</div>
<div id="ref-Savazzi2011" class="csl-entry" role="listitem">
Savazzi, Enrico. 2011. <em>Digital Photography for Science</em>. Lulu Press, Inc.
</div>
<div id="ref-Stott2025" class="csl-entry" role="listitem">
Stott, David, Anna K. Tjelldén, Jens Berthold, Jonathan M. Crowther, Lars Krants Larsen, Michael S. Thorsen, and Søren M. Kristiansen. 2025. <span>“Seeing the Past in a New Light: LED Multi-Spectral Imaging as an Interpretative Aid for Archaeological Excavation.”</span> <a href="https://doi.org/10.2139/ssrn.5152881">https://doi.org/10.2139/ssrn.5152881</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./quantifying-responses.html" class="pagination-link" aria-label="Quantifying plants' responses">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Quantifying plants’ responses</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./design-of-experiments.html" class="pagination-link" aria-label="Design of Experiments and Statistics">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Design of Experiments and Statistics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Imaging in UV, VIS and NIR radiation"</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Equipment and methods"</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Pedro J. Aphalo"</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggspectra)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyFilters)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyLamps)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyLEDs)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(photobiologyPlants)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="fu">photon_as_default</span>()</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="fu">Tfr_as_default</span>()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="fu">set_theme</span>(<span class="fu">theme_bw</span>())</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>With some exceptions, producing photographic images, either photo-electronically or photo-chemically, requires a camera, a lens and a light source. To limit the imaging to specific regions of the spectrum, optical filters are used. Illumination can be sunlight or artificial. If artificial it can have a broad spectrum or be limited to a specific range of wavelengths.</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>Most frequently, landscape and other types of low magnification and even macro photography are based on reflected light. In microscopy it is common to image the light transmited through a specimen. Imaging of fluorescence is also used in the plant sciences in relation to photosyntheis and other pigments, and in microscopy. In this chapter, we exclude high magnification microscopy, and concern with photography at magnifications of less than $\times 5$.</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>Black and white (grey scale) images contain only brightness information, which can be intuitively mapped also in images obtained at wavelengths invisible to humans. In contrast, colour photographs are intuitively expected to represent colours as seen by humans. When mapping wavelengths invisible to us into colours, the choice of mapping stops being obvious, and different more or less arbitrary mappings can be used. In some cases, the mapping is just accidental, as a consequence of the properties of the R, G, and B filters of image sensors in the UV or NIR regions, wavelengths not taken into account in their design.</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>This chapter is structured in sections describing cameras, lenses, filters, light sources and accesories. Image editing and special techniques based on image merging are discussed next. These sections are followed by a description of example setups and procedures for UV, VIS, and NIR imaging, fluorescence imaging, as well as macro photography. A whole book could be written on the subject but this chapter intends to be an introduction to imaging methods of special interest to photobiologists. </span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Types of cameras</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="fu">### Digital photographic cameras</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>It is usual to call cameras with interchangeable lenses "system cameras" and those with a lens permanently afixed, usually smaller in size and with no or with limited or akward to use manual settings "point-and-shoot" cameras. There are some cameras that do do not fit into these two categories, e.g., with full manual controls and relatively large sensors with no possibility to change lenses. Cameras in these different categories can be useful in scientific research, but not interchangeably. Their advantages and disadvantages determine their suitability. Even smart phone cameras, can occasionally be useful for more than "visual note taking" <span class="co">[</span><span class="ot">@fig-photography-cameras</span><span class="co">]</span>. </span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>::: {#fig-photography-cameras layout="<span class="co">[</span><span class="ot">40,60</span><span class="co">]</span>"}</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="al">![OM-1](temporary-images/om-1-mark-ii-12-40mm-pro-kit-top.webp)</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a><span class="al">![TG-7](temporary-images/tough_tg-7_-_techspecs_image.webp)</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>A mirrorless camera (OM-1) with an interchangeable lens and a hardened point-and-shoot camera (TG-7) with a fixed zoom lens,. The OM-1 is splash and dust proof and rated to function from -20 to +40 C, altough in practice can be used at lower temperatures. The TG-7 is named "tough" and designed to work without additional protection both in air and down to a depth of 15 m in water, to survive forces of up 100 kg and falls from a height of 2.1 m.</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>Digital cameras sold for amateur and professional photography are self contained: all controls, viewfinder and/or live-view screen, image review and image data storage all take place in-camera. Modern cameras are also capable of complex image processing. These cameras are primarily battery powered althougn some can be in addition powered externally. Most cameras for ordinary photography are designed for imaging reflected visible light. In a few cases, manufacturers have offered versions of these cameras for use in forensics or astronomy, with extended wavelength range (e.g., OM-3 ASTRO Mirrorless Camera, OM-System).</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>Normal photographic cameras aim at producing images that depict a scene as seen by humans, and, thus, are most sensitive to the central wavelengths of visible light ($\approx 410-680$ nm). When producing colour images, image sensors with three colour channels are used, with each channel's colour response designed to approximately mimic the spectral sensitivity of one of the three photoreceptors participating in human day-time vision. This tight link to human vision also applies to the implementations of colour film, video, TV and computer monitors. Colour printing is more complex as inks are in most cases opaque making their effect on reflection non-additive, but printing also exploits the "deficiencies" of our eyes to trick us into seeing colours. </span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>In the case of monochrome or greyscale (= black and white, BW) photographic films used for everyday photography and the very few monochrome digital photographic cameras available, the images produced aim at depicting the brightness of an scene as seen by humans. _In other words, normal photographic and video cameras are designed to work as proxies for human three-chromic vision, not as spectrometers_.</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>Most digital photography cameras capture colour images and have sensors with red, green and blue filters on individual pixels. Monochrome cameras have sensors lacking such filters. So each pixels in the sensor receives more photons. In addition, the lack of filters makes raw image processing straightforward with all individual pixels providing equivalent data. This results in a higher apparent spatial resolution and higher dynamic range. Currently, there are four monochromatic (or greyscale) digital photographic cameras available: Leica M11 Monochrom, Leica Q3 Monochrom, Leica Q2 Monochrom and Pentax K-3 Mark III Monochrome. A monochrome point-and-shoot camera has been announced by Ricoh.</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a><span class="fu">### Digital image sensors</span></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>Image sensors are two-dimensional arrays of photodetectors. The main determinant of the native wavelength sensitivity is the material used. Most VIS (really 320 to 1000 nm) sensors are made of silicon (Si) using CMOS or CCD approaches. The size of individual photosites and the speed of their readout varies. There is normally a compromise between the number pixels (amount of data to be acquired) and the speed of image acquisition measured in frames per second (fps). The whole sensor array in constructed by etching and deposition similarly to how electronic integrated ciscuits are made.</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>The wavelength range can be constrained with optical filters, on individual photosites, small groups of photosites, or the whole image sensor.</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>The sensors used in photographic cammeras are natively sensitive to wavelengths in the range $\approx 330-1100$ nm and the R, G and B filters, do transmit outside the VIS range. At both ends of this range, sensitivity ($\approx$ quantum yield) decreases very gradually. In photographic cameras, the wavelength range is constrained by an optical UV and IR cut filter attached to the front of the whole sensor assembly to create a wavelength response closer to that of human vision. Depending on the camera, the shortest wavelengths that are detected by the sensor plus filter combined vary between $370 nm$ and $420 nm$, and the longest ones between $680 nm$ and $730 nm$. The filters used are frequently absoptive ionic and the cut-in and cut-off, specialy at the NIR end, is gradual, i.e., in most digital photography cameras it is possible to use a $720 nm$ long-pass filter to take images in the NIR but only by increasing exposure by orders of magnitude.</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>It is possible to _convert_ cameras to _"full spectrum"_ (meaning the native sensitivity of the sensor with its R, G and B filters) by replacing the sensor filter with quartz glass or a long-pass filter with a suitable cut-in, such as at 280 nm. In a _"full spectrum"_ converted camera additional filters can be used in front or behind the lens to restrict the wavelength range as needed. Alternatively a camera can be modified to be constitutively sensitive to a especific range of wavelengths installing a wavelength-selective filter onto the sensor. </span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a>Conversion involves disassembling the camera but is relatively simple, and costs between 200 € and 500 € depending on the camera model and who does the conversion. In a _"full spectrum"_ or _"filter"_ conversion, the sensor itself in not modified, and the RGB filters remain on the sensors pixels. Several companies, both is the USA and in Europe do conversions, but not all of them are equally reliable. </span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>The conversion of a colour camera into a monochrome camera is much more difficult and there is a risk of damaging the sensor making it unusable, as it involves the removal filters that are part of the sensor itself. Very few companies do this type of conversion, charging from 1200 € to &gt; 1500 €, usually only accepting for conversion specific models or brands of cameras. A _"full spectrum monochrome"_ conversion is also possible, either by modifying a natively monochrome camera or by removal of R, G and B filters plus replacement of Uv and IR cut filter.</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a><span class="fu">### False colour in UV-A and NIR</span></span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>In a full-spectrum-converted camera the R, G, and B filters on the sensor array remain. These filters also differ in their transmittance for wavelengths in the UV-A and NIR regions, thus, in UV-A and NIR the R, G, and B channels in the sensor respond differently to different wavelengths, even in the absence of red, green and blue light. When the data are "interpreted" by the software (raw converter) as for visible light a false-colour image results. Depending on the case the false colour can be informative or a nuisance. If found a nuisance or confusing the image can be converted from _colour_ into _greyscale_ based on the three channels or by extracting the data for a single colour channel.</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>A camera converted to "full-spectrum" is usefully sensitive to an extended range of wavelengths of approximately 340 nm to 1000 nm. This range can be constrained by means of optical filters attached either in front or behind the lens. Thus, a "full-spectrum" converted camera can be used for UV-A, VIS or NIR photography by swapping filters. Having a camera sensitive to a wider range of wavelengths is only one requirement, an objective (= lens) that transmits and performs well in the UV and NIR regions is also needed.</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### Head-less specialised cameras</span></span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>The cameras most frequently used for photography have a live-view screen or a viewfinder that makes framing and focusing possible. In contrast, machine vision cameras used in industrial automation and cameras for astronomy, microscopy and other scientific uses are designed to be used thetered to a computer (rarely to a tablet or smartphone), and in most cases lack a means to display images. Headless cameras lack or have minimalistic controls, they are designed to be controlled remotely. They can be thetered to a nearby computer using USB or similar connection, or to farther away devices through a LAN or the internet, and controlled of supervised either by a human operator or automatically bt software <span class="co">[</span><span class="ot">@fig-headless-camera</span><span class="co">]</span>.</span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a> These cameras are frequently called following computing jargon as being "headless" cameras.</span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>::: {#fig-headless-camera layout="[<span class="co">[</span><span class="ot">60,40</span><span class="co">]</span>, <span class="co">[</span><span class="ot">60,40</span><span class="co">]</span>]"}</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a><span class="al">![GXVISION monochrome camera based on OMNIVISION’s OV9281 image sensor](temporary-images/GXVISION-OV9281-120fps-USB-Monochrome.png)</span></span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a><span class="al">![Rapsberry Pi camera 3 based on the Sony IMX708 sensor](temporary-images/Pi-camera-3.png)</span></span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a><span class="al">![LUCID Triton Industrial machine vision camera](temporary-images/Lucid-Triton-IP67.png)</span></span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a><span class="al">![.pco PANDAS 26 USB microscopy camera](temporary-images/sCMOS-Excelitas.jpg)</span></span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a>Two examples of very cheap headless cameras, and two examples of expensive cameras. A monochrome "machine vision" camera with global shutter and capable of 120 fps, but low resolution of 1 M pixel, from Gxvision (China) and of a Rapsberry Pi model 3 camera 11 M pixel. Both cameras are small and cost less than 50 €. LUCID's Triton is a very small 20 MP camera capable of 5.5 fps in rugged metal case with IP67 ingress-protection rating available for about 500 €. Excelitas .pco PANDAS 26 USB camera has a 26 MP sensor and supports exposure times between $27\,\mu s$ and $12\,s$ with a global electronic shutter. It sells for approximately 10\,000 €.</span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>Specialised digital cameras used in industrial automation (= "machine vision"), astronomy, microscopy, etc., frequently use the same or similar image sensors as photographic cameras, but unusual wavelength sensitivity ranges are more common. Monochrome head-less cameras are also more abundant than monochrome photographic cameras. Digital NIR cameras are common, i.e., sold as surveilance and "night-vision" cameras. Cameras for UV-A are rather common for especific uses, as many Si-based sensors are natively sensitive to it. Very few digital cameras designed for UV-B and even UV-C imaging are available, based on especialized sensors with an extended wavelength sensitivity range. One example is LUCID's Atlas10 UV camera based on Sony's IMX487 UV sensor, recomended for imaging in the range 200 to 400 nm. This new UV sensor produces 8 MP images at up 137 fps. At the other edge of the VIS band</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a>LUCID's Atlas10 SWIR camera based on Sony's IMX992 TE-cooled SWIR image sensor is usable for imaging in the range 400 nm to 1700 nm at 119 fps. These momochrome cameras although aimed at industrial inspection and garbage sorting cover wavelengths of special interest in plant photobiology research and close-range remote sensing.</span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>While many headless cameras are intended to be mounted at a fixed position, others are suitable for use in drones. While industrial cameras are built for a harsh environemnt those for use in drones are smaller and lighter. In most cases these cameras produce live images, and can be fully controlled remotely. They are connected either "by wire" (ethernet or USB interfaces) or wirelessly (Wifi). Given that they are not used handheld but instead fixed and in many cases continuosly switched on, they in most cases lack an internal battery and depend on an external power source such as a mains adapter, power over ethernet, USB or external battery.</span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a>Being especialised some of these cameras have features not available in consumer or professional photographic cameras.</span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a>They are in many cases available with sensor variants with or without NIR and/or UV blocking filters and in versions with colour or monochrome sensors. Recently Sony has announced an image sensor with sensitivity reaching UV-C and is likely to target industrial and scientific uses.</span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a>Some modern photographic cameras can capture bursts of images at frame rates of 200 fps. Some of the cameras used for machine vision and research are capable of capturing images at even faster rates (e.g., $1\,000$ or even $1\times 10^6$ fps). Other cameras, such as those used for astronomy, have sensors with a very low dark noise floor, usually with thermoelectric cooling, able to capture images at very low light levels using very long exposure times.</span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a>There is also a range of cheaper cameras sold for use with microcontrollers (MCB, e.g., Arduino UNO, or ESP32 boards) or single-board computers (SBC, e.g., Raspberry Pi). Some of these cameras are available in two versions with and without a NIR-blocking filter. There are different models available, some with very small sensors selling for as little as 15 € while others with sensors similar to those used in good smartphones available for close to 100 €. Some of these cameras support relatively high frame rates but have low resolution while others have higher resolution but lower frame rates. A few even have autofocus. These cameras are used thetered to a MCB or a SBC using interface protocols supported almost exclusively by such boards. The connection to the boards is wired and at very short distances. Remote and local access is through the controller board. The MCB plus camera can thus function as a bare bones headless camera.</span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a>More recently very small boards based on ESP32 microcontrollers have become available with built-in cameras and able to connect through wireless prococols like Wifi, Bluetooth and Matter. The image sensors used in these cheap cameras even if in some cases have high pixel resolution have small pixels (small light capture area), and even if they can work resonanbly well under good illumination, image quality under weak light is poorer than with more expensive cameras, but still useful. This is the realm of the internet of things (IoT) where rapid progress is taking place. For example, some cheap boards are based on microprocessors well suited for image analysis and pattern recognition using pre-trained AI models.</span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a><span class="fu"># Films for infrared photography</span></span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>With the adoption of digital cameras, many types of photographic films have been discontinued. Films with extended NIR sensitivity were frequently used for aerial photography, both in grey scale and false-colour types. Only a couple of types of grayscale "IR", really extended-red-sensitivity, film are still available (e.g., Ilford SFX 200). These films are sensitive up to $\approx 730-770$ nm depending on brand and type. Normal film types used for visible light are sensitive to UV-A to a larger or smaller extent while no special films for UV are available.</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a><span class="fu">### Spectral and hyperspectral cameras</span></span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>Spectral cameras cover the VIS wavelength range with more than three "colour" channels, achieving better wavelength resolution and reducing or avoiding _metamerism_. These cameras acquire a spectrum for each pixel in the acquired image. Hyperspectral cameras frequently cover a wider range of wavelengths and have relatively high wavelength resolution. Multispectral cameras are sensitive to only a few specific narrow wavelength ranges. However, different manufacturres not necessarily use the same naming criteria. Most of the these cameras cover the VIS and/or NIR but very rarely UV.</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a><span class="fu">### Metamerism</span></span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a>Metamerism is inherent to the extractiion of detailed colour information using few detectors with partly overlapping wavelength sensitivity ranges. It results for such systems, including human vision, being unable to distinguish between some combinations of wavelengths from pure monochromatic light. This is the basis of the trick that creates "yellow", "purple" and many other colours in a monitor or TV set capable of emiting only red, green and blue light.</span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a>Different spectral cameras use different approaches for image acquisition. Based on this, two distinct types are recognizable: 1) scanning cameras and 2) snapshot cameras. Scanning cameras acquire images one row of pixels at a time, i.e., they usually have high wavelength resolution but are not suited for fast moving subjects. Snapshot cameras acquire data for all pixels within a small fraction of a second, have lower wavelength resolution and can be used to image faster moving subjects. Cameras from two large suppliers are mentioned below, only as examples.  </span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Cubert</span><span class="co">](https://cubert-hyperspectral.com/en/)</span> specialises in **snapshot spectral cameras**, based on different implementations. The most advanced of their cameras use a light-field-based technology that allows both high spatial and high wavelength resolution (e.g., 410 x 410 pixels, 350–1000 nm, 164 wavelength bands, FWHM 10 nm, max 4 fps for the very small Cubert Ultrix X20).</span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Specim</span><span class="co">](https://www.specim.com)</span> specialises in **line scan cameras** _push broom_ cameras. These cameras are available in VIS versions and different VNIR, NIR and IR versions, reaching even thermal radiation wavelengths. Modern line cameras are faster than previous models (e.g., 400-1000 nm, 224 wavelength bands, FWHM 5 nm, 1024 pixels / line, xxxx fps depends on settings, for the Specim FX10).</span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spectral imaging with non-spectral cameras</span></span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a>Photography captures light reflected by the objects being imaged. Spectral reflectance can be measured in two ways: 1) under white illumination with a sensor or film that discriminates among wavelengths of the reflected light, 2) under white illumination and multiple images each taken using a different band-pass optical filter, using a sensor or film sensitive to a wide range of wavelength without discriminating among them, or 3) by sequential illumination with light of different wavelengths and multiple monochrome images. The first approach is normally used in colour photography using optical filters on the sensor or in the film. The second approach in different variations was the basis of early methods of colour photography, persisting until the 1950's. The third approach is not in widespread use, but used in at least one currently available "spectral" inaging system for plant phenotyping (RAYN Vision System Camera, <span class="co">[</span><span class="ot">Rayn Growing Systems</span><span class="co">](https://rayn.ag/)</span>). This approach has been also shown to be applicable in the field at archeological sites to identify layers in the soil profile <span class="co">[</span><span class="ot">@Stott2025</span><span class="co">]</span>. As the approach can be easily and cheaply implemented using a normal camera or even a SBC together with a cheap dedicated camera it is a promising approach for in-place plant phenotyping in controlled environments.</span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a>On the other hand, digital photographic camera sensors have nowadays fast readout times, making the capture of fast sequences of images possible with this more expensive cameras. Techniques based on merging images to create a multichannel image cube, increase image resolution, increase the depth of the in-focus region or enhance image dynamic range could be potentially combined with illumination with light of different wavelengths. Photographs from a test using a seven-channels LED array are shown in @fig-spectral-photos.</span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a>::: {#fig-spectral-photos}</span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a><span class="al">![Images, not edited](temporary-images/spectral-frames-7chn-colour.jpg)</span>{group=spectral-pansies}</span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a><span class="al">![Images, white balanced](temporary-images/spectral-frames-7chn-balanced.jpg)</span>{group=spectral-pansies}</span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a><span class="al">![Images, grey scale converted](temporary-images/spectral-frames-7chn-gray.jpg)</span>{group=spectral-pansies}</span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a>Images acquired with an OM-1 digital camera with the subjects illuminated with a six-colours plus white LED array, using each channel in turn as light source. See <span class="co">[</span><span class="ot">on-line article for the details</span><span class="co">](https://www.photo-spectrum.info/pages/illumination/spectral-imaging.html)</span>.</span>
<span id="cb12-152"><a href="#cb12-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-153"><a href="#cb12-153" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-154"><a href="#cb12-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-155"><a href="#cb12-155" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-156"><a href="#cb12-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-157"><a href="#cb12-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Thermal cameras</span></span>
<span id="cb12-158"><a href="#cb12-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-159"><a href="#cb12-159" aria-hidden="true" tabindex="-1"></a>Thermal IR cameras, designed for temperature measurements are monochromatic and sensitive to radiation in the range $8\,\mu m$ to $14\,\mu m$ (for $-20^\circ\mathrm{C}$ to $1500^\circ\mathrm{C}$), $0.85\,\mu m$ to $1.1\,\mu m$ (for $450^\circ\mathrm{C}$ to $1800^\circ\mathrm{C}$, used for hot metal), and variations. As with other cameras, both thermal cameras with a built-in display and headless ones are available. There are available even miniature thermal cameras designed to be attached to smart phones.</span>
<span id="cb12-160"><a href="#cb12-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-161"><a href="#cb12-161" aria-hidden="true" tabindex="-1"></a>::: {#fig-thermal-cameras}</span>
<span id="cb12-162"><a href="#cb12-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-163"><a href="#cb12-163" aria-hidden="true" tabindex="-1"></a><span class="al">![Thermal image as grey scale](temporary-images/)</span></span>
<span id="cb12-164"><a href="#cb12-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-165"><a href="#cb12-165" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-166"><a href="#cb12-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-167"><a href="#cb12-167" aria-hidden="true" tabindex="-1"></a>In the case of these cameras, no wavelength information is captured, only the emitted NIR radiation flux. This energy flux is converted into an estimate of surface temperature based on the known or assumed emittance of the objects in the image. Data are temperatures, one for each pixel. When false colours are used, they represent different temperatures.</span>
<span id="cb12-168"><a href="#cb12-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-169"><a href="#cb12-169" aria-hidden="true" tabindex="-1"></a>::: {#fig-thermal-image}</span>
<span id="cb12-170"><a href="#cb12-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-171"><a href="#cb12-171" aria-hidden="true" tabindex="-1"></a><span class="al">![Thermal image as grey scale](temporary-images/thermal-faba-at-night-gray.jpg)</span>{group=thermal-faba}</span>
<span id="cb12-172"><a href="#cb12-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-173"><a href="#cb12-173" aria-hidden="true" tabindex="-1"></a><span class="al">![Thermal image as false colour](temporary-images/thermal-faba-at-night-colour.jpg)</span>{group=thermal-faba}</span>
<span id="cb12-174"><a href="#cb12-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-175"><a href="#cb12-175" aria-hidden="true" tabindex="-1"></a>Thermal image of *Vicia faba* plants of two different genotypes differing in stomatal conductace. Leaves of plants on the left, seen darker or blue, are at near 20 C and those on the right, seen lighter or green, are at near 22 C. The pots and boxes, seen almost white or red, are at more than 25 C.</span>
<span id="cb12-176"><a href="#cb12-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-177"><a href="#cb12-177" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-178"><a href="#cb12-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-179"><a href="#cb12-179" aria-hidden="true" tabindex="-1"></a>When using a thermal camera it is important to be aware that objects that look transparent to us, like a glass window, are in most cases opaque to NIR. A thermal image of a window, will show its temperature, not of what is behind it. Given the very high NIR reflectance of aluminium if we point the camera at an aluminium sheet, the image will show like on a mirror, the image of the camera and the operator! The temperature recorded by the camera will better reflect our own and the camera's temperature than the temperature of the aluminium sheet.</span>
<span id="cb12-180"><a href="#cb12-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-181"><a href="#cb12-181" aria-hidden="true" tabindex="-1"></a>As glass is not transparent to NIR wavelengths sensed by thermal cameras, lenses and NIR windows are made of other materials, such a Germanium.</span>
<span id="cb12-182"><a href="#cb12-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-183"><a href="#cb12-183" aria-hidden="true" tabindex="-1"></a><span class="fu">## Objectives</span></span>
<span id="cb12-184"><a href="#cb12-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-185"><a href="#cb12-185" aria-hidden="true" tabindex="-1"></a><span class="fu">### Photography objectives</span></span>
<span id="cb12-186"><a href="#cb12-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-187"><a href="#cb12-187" aria-hidden="true" tabindex="-1"></a>The focal length of an objective determines the size of the projected image. Camera lenses with a fixed focal lens are called "prime lenses" and lenses with a variable focal lenght are called "zoom lenses". A _normal_ focal length is one that approximates the field of view of human vision (ignoring periferical vision). For a rectagular "frame" this corresponds to an angle of view of approximately $45^\circ$ measured on its diagonal. Film sizes as well as digital sensor sizes as well as their aspect ratio vary. Thus, the "normal" focal length depends on the film or sensor size of the camera. Camera lenses with shorter focal length than "normal" provide a broader field of view and are called "wide angle lenses". Those with focal length longer than "normal" are called "tele objectives". "Tele-converters" are lenses that modify the focal length of other lenses by increasing it. The less common "speed boosters" change the effective focal length in the opposite direction, widening the field of view, and consequently increasing the photon flux reaching the sensor or film.</span>
<span id="cb12-188"><a href="#cb12-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-189"><a href="#cb12-189" aria-hidden="true" tabindex="-1"></a>Lenses designed for different sensor or film sizes project images of a size that roughly matches them. The diameter of the "image circle" that lenses project at the plane of the film or sensor usually only slightly exceeds the length of the diagonal of the sensor or film frame. This is in large part driven by the desire to keep lenses light in weight and small in size. Additionally, a smaller area unecesarily illuminated outside the sensor or film, fewer problems with light reflections inside the camera. </span>
<span id="cb12-190"><a href="#cb12-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-191"><a href="#cb12-191" aria-hidden="true" tabindex="-1"></a>"Speed-booster" auxiliary lenses can be used only together with lenses having an image circle larger than necesary for the sensor in use, i.e., designed for a larger sensor or film size than the one being used.</span>
<span id="cb12-192"><a href="#cb12-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-193"><a href="#cb12-193" aria-hidden="true" tabindex="-1"></a>In addition to angle of view, focusing distance determines magnification. Modern general-purpose camera lenses tend to perform very well from far to close distances, and in general have the minmum focusing distance nearer than "classical" lens designs from half a century or longer ago. Special lenses for macro photography remain relevant, as the magnification they achieve at their closest focusing range has also increased compared to that achieved with older designs. One extreme case is the M.Zuiko 90 mm f3.5 Macro lens from OM-System (formerly Olympus) that at its highest magnification the whole sensor image corresponds to $4 \times 3\,\mathrm{mm}$ on the photographed subject. This objective performs flawlessly from this closest focusing distance all the way to infinity focus.</span>
<span id="cb12-194"><a href="#cb12-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-195"><a href="#cb12-195" aria-hidden="true" tabindex="-1"></a>Modern camera lenses use (very) complex designs, and because of this, they sometimes seem to disobey the laws of optics. Many profesional lenses have internal focusing mechanisms that displace only some optical elements, while in classical lens designs focusing was achieved by changing the distance between the lens as a whole and the film. One reason for the adoption of internal focusing is the widespread reliance on auto-focus. Reducing the mass of glass that needs to move alows faster focusing using less energy, two crucial goals in modern lens design. Some lenses have multiple optical groups that move relative to other when focusing or zooming.</span>
<span id="cb12-196"><a href="#cb12-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-197"><a href="#cb12-197" aria-hidden="true" tabindex="-1"></a>Most modern lenses are sharp enough for most uses, even those aimed at "consumers" rather than "professionals", or even many, but not all, medium priced Chinese lenses. Things that can be better in professional lenses are: faster auto-focus, wider maximum apertures ("faster lenses"), image stabilization, weather-sealing, rugged construction, smoother-looking out-of-focus areas (= better bokeeh), and to some extent better control of in-lens reflections. Generally, profesional lenses are easier to use or perform better in extreme or difficult situations and are designed to withstand more intense use. For example _some_ professional cameras and lenses can be safely used in heavy rain or under low freezing temperatures without any special protection. From a user perspective, profesional lenses tend to maintain a proportionaly higher resale value for a longer time that cheap consumer lenses. This relates to both their sturdier build, lower availabilty and depending on brand, also easy of repair.</span>
<span id="cb12-198"><a href="#cb12-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-199"><a href="#cb12-199" aria-hidden="true" tabindex="-1"></a><span class="fu">### Objectives for UV and NIR photography</span></span>
<span id="cb12-200"><a href="#cb12-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-201"><a href="#cb12-201" aria-hidden="true" tabindex="-1"></a>For an objective to be suitable for UV or NIR photography it has to have reasonably high transmittance of the wavelengths to be captured in the image and it has to be _corrected_ for image aberrations and other problems at these same wavelengths. There exist very few camera objectives that can transmit and are corrected for UV-A, UV-B and even UV-C, and those that exist are extremely expensive ($&gt; 10\,000$ €) and fragile. I will not discuss such objectives further, as I never had access to one. Instead, I will discuss the cheaper alternative of using normal objectives. Three main difficulties are usually encountered when attempting to use normal objectives: transmittance limited to UV-A1 and longer wavelengths, ghosting and haze, and optical aberrations than can decrease image resolution and/or decrease contrast.   </span>
<span id="cb12-202"><a href="#cb12-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-203"><a href="#cb12-203" aria-hidden="true" tabindex="-1"></a>Most modern, and many vintage, objectives have very low transmittance in the UV region. In addition to the cut-in wavelength, the shape of the transmission spectrum varies depending on the lens. The reason for this is in the glass used, its thickness, the cemment used to assemble lens groups and the properties of the antireflection coatings applied. A general "wisdom" not free of exceptions is that the more elements (more surfaces with coatings) and the thicker these glass elements are, the less likely an objective is to have good UV transmission. This usually means that simpler designs and slower (smaller maximum apperture) objective are more _likely_ to transmit some UV-A radiation. </span>
<span id="cb12-204"><a href="#cb12-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-205"><a href="#cb12-205" aria-hidden="true" tabindex="-1"></a>In general, older or "vintage" objectives had simpler designs and less effective coatings and as a result more frequently objectives based on old designs have higher UV-A1 transmittance. The modern exceptions are a few inexpensive objectives, including some autofocus ones. In general, accidental UV objectives are "prime lenses" (fixed-focal-length objectives) not zooms or extreme wide-angle. It is usual to describe objectives that are not designed for use in UV, but happen to work reasonably well as _"accidental" UV-capable objectives_.</span>
<span id="cb12-206"><a href="#cb12-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-207"><a href="#cb12-207" aria-hidden="true" tabindex="-1"></a>It is not enough for a lens to have good transmittance as internal reflections can deteriorate the quality of images. To prevent reflections non-glass internal surfaces inside the "barrel" of objectives and the edges of glass (or plastic) optical elements are painted or treated black. Coatings and surfaces that have very low reflectance in the VIS region not necessarily have the same property outside the VIS region. One rather extreme case is black-annodized aluminium which is highly reflective in the NIR region.</span>
<span id="cb12-208"><a href="#cb12-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-209"><a href="#cb12-209" aria-hidden="true" tabindex="-1"></a>When using objectives designed for VIS photography for NIR, problems tend to be different than with UV. Most photography objectives have rather high transmittance in the relevant part of the NIR region (700 to 1100 nm). However, when used in NIR many photography lenses produce images with _hot spots_ (usually near the center of the image) as a result of internal reflections. In most cases this problem is more noticeable at specific appertures. Ghosting caused by specular reflections within the lens is visible in images as bright spots with the shape of the diaphrogm apperture (the opening or "hole"). Flare, caused by scattered reflected light results is a decrease in image contrast. Although there are many more objectives suitable for NIR photography than for UV-A photography, it is important to keep in mind that some objectives produce better images than others.</span>
<span id="cb12-210"><a href="#cb12-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-211"><a href="#cb12-211" aria-hidden="true" tabindex="-1"></a>Chromatic aberrations, which can affect UV, VIS and NIR, appear when the path of light of different wavelengths through a lens differs. For example, when a white object is photographed, the red, green and blue components can be slighly displaced from each other when projected on the sensor or film. In digital photographs chromatic aberretations are visible in high contrast edges as coloured halos. Most ordinary photography objectives are corrected for these aberrations by design only in the VIS range, thus, how objectives behave outside this range is an "accident". Given the nature of these aberrations the narrower the range of wavelengths captured, the less likely it is that they will affect an image.</span>
<span id="cb12-212"><a href="#cb12-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-213"><a href="#cb12-213" aria-hidden="true" tabindex="-1"></a>The design of any objective is a compromise among multiple goals reflected in design criteria, related not only to image quality, but also usability, size, weight and cost of manufacture. The design of different objectives is based on a different compromise. In spite of this, some objectives happen to work reasonably well outside the range of wavelengths for which their design was optimized. They never match the performance of objectives designed for UV photography, which can be used all the way to 250 nm or even shorter wavelengths. However, these extremely expensive and fragile objectives are overkill when the sensor of a camera is only sensitive to $\lambda &gt; 330\ldots350$ nm.</span>
<span id="cb12-214"><a href="#cb12-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-215"><a href="#cb12-215" aria-hidden="true" tabindex="-1"></a>Finding a good accidental UV objective is made easier by lists published on the internet. Similar lists exist for objectives that are free of hot-spot problems. These lists are in many cases based on informal tests using different criteria and methods depending on the contributor of the data. They serve mainly as an indication, but provide no guarantee. In addition, many now vintage lenses were manufactured during several decades, with occasional changes in antireflection coatings or other alterations to their design that can affect UV transmittance. There are a couple of modern objects, available new until a few years ago, that do transmit UV-A1, support autoexposure, and with strong illumination even autofocus in UV-A1.</span>
<span id="cb12-216"><a href="#cb12-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-217"><a href="#cb12-217" aria-hidden="true" tabindex="-1"></a>In the case of hot spots under NIR, the assessments on which the lists are based are even more subjective than for UV as they are usually based on visual assessment of images. As hot spots are reflections they are highly dependent on the position of light sources. How visible or disturbing they are depends on the subject matter photographed as they are more disturbing on dark than on bright images. In the case of NIR, many modern as well as old objectives can be used at least at some appertures.</span>
<span id="cb12-218"><a href="#cb12-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-219"><a href="#cb12-219" aria-hidden="true" tabindex="-1"></a>When using vintage objectives on modern cameras one needs to rely on adapter rings, and when using non-macro objectives for macro photography, extenssion tubes have to be inserted between the objective and the camera. Quite frequenty one can find statements that such tubes without any glass cannot degrade image quality. This is far from true, and frequently a problem, especially for NIR photography. Many cheap adapters and extension tubes are made of aluminium made black by anodization and are internally highly reflective to NIR radiation. Even if black, they can be shiny enough to also degrade image quality in VIS light. It is common that in good quality adapters and extension tubes, as well as in objectives, the inside is ribbed perpendiculalry to the axis of the objective. The ribbing helps control especular reflections, and when combined with a non-reflecting black paint, is very effective. If the ribbed surface is reflective, light is scattered and glare affects the image. It is possible to paint the interior wall of extension tubes and adapters oneself if the manufacturer has not done so. The choice of paint is important as only some special paints absorb 95% or more of NIR and UV. That a paint is black in the VIS region gives no guarantee of it being UV and/or NIR "black". </span>
<span id="cb12-220"><a href="#cb12-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-221"><a href="#cb12-221" aria-hidden="true" tabindex="-1"></a>Reflections are not the only problems low quality adapters and tubes can introduce. If the dimensions of the mounts and especially the length of adapters is wrong, focusing at infinity can become impossible and the distance markings on focusing rings biased. This effect is most noticeable with wide angle objectives, e.g., for a fisheye objective with a focal length of 4.5 mm, the required accuracy in the adapter is a very small fraction of a millimetre. It is important to be aware of these possible problems. If the adapters are too short adding shims to slightly raise the lens-side mount of the adapter is possible in some cases. A shim is a usually a think metal sheet, in the case of lenses ring-shaped. For tube diameters used in telescopes shims are readily available in thicknesses varying from 0.1 mm to  1 mm or more. Lacking metal shims, hard plastic can also be used. </span>
<span id="cb12-222"><a href="#cb12-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-223"><a href="#cb12-223" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optical filters</span></span>
<span id="cb12-224"><a href="#cb12-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-225"><a href="#cb12-225" aria-hidden="true" tabindex="-1"></a>Optical filters select wavelengths through absortion and/or through reflection. Each type has its limitations and benefits, both in performance and cost. How good a filter is needed depends on multiple factors, including illumination spectrum and irradiance compared to the strength of the radiation captured in the image. As fluorescence of plants has in geenral a rather low quantum yield, photographying fluorescence requires filters that block out-of-band radiation extremely well ($\approx \mathrm{OD} &gt;= 5$, or $T &lt;= 0.00001$). UV-A photography in sunlight is not so challenging, but still many filters do not block NIR or VIS well enough ($\approx \mathrm{OD} &gt; 3$, or $T &lt; 0.001$, is usually recommended).</span>
<span id="cb12-226"><a href="#cb12-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-227"><a href="#cb12-227" aria-hidden="true" tabindex="-1"></a>**Absorptive glass filters** are based on "ionic" glass, i.e., glasses including different ions in their composition. Some of the ions tradditionaly used are metals like iron, lead, copper and chrome. As with any material absorbing photons, fluorescence is one of the possible energy dissipation mechanisms. Thus, some of these filters, e.g., when illuminated with UV-A radiation emit fluorescence in the visible range, and others emit NIR fluorescence when illuminated with blue light. The absorptance depends on their thickness as the glass as a whole has uniform properties across its depth. The change in the absorptance spectrum with the angle of light incidence is moderate. Their cut-offs and cut-ins are gradual, and these filters are available as band-pass, short-pass and long-pass filters (@fig-img-filters-ionic). From the perspective of their use, as the transmitted bands are broad, the distinction between short-pass and band-pass gets blured, i.e., most UV-A and UV-B "short-pass" filters are really band-pass filters as they do block UV-C wavelengths. Ionic-glass are not good enough for fluorescence or UV imaging, but work well for refelcted NIR photography. One exception to this rule is that very thick glass filters can have high out-of-band absorptance with not to low in-band transmittance (e.g., TSN340 from Tangsinuo is a glass filter about 10 mm-thick). </span>
<span id="cb12-228"><a href="#cb12-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-231"><a href="#cb12-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-232"><a href="#cb12-232" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-img-filters-ionic</span></span>
<span id="cb12-233"><a href="#cb12-233" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.90</span></span>
<span id="cb12-234"><a href="#cb12-234" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-235"><a href="#cb12-235" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Total transmittance spectra of two absoptive ionic filters. A short-pass UV filter (UG1 fron Schott) and a long-pass NIR filter (RG695, from Schott).</span></span>
<span id="cb12-236"><a href="#cb12-236" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-237"><a href="#cb12-237" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">convertTfrType</span>(filters.mspct[<span class="fu">c</span>(<span class="st">"Schott_RG695"</span>, <span class="st">"Schott_UG1"</span>)],</span>
<span id="cb12-238"><a href="#cb12-238" aria-hidden="true" tabindex="-1"></a>                        <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb12-239"><a href="#cb12-239" aria-hidden="true" tabindex="-1"></a>                        <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb12-240"><a href="#cb12-240" aria-hidden="true" tabindex="-1"></a>                        <span class="at">facets =</span> <span class="dv">1</span>)</span>
<span id="cb12-241"><a href="#cb12-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-242"><a href="#cb12-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-243"><a href="#cb12-243" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb12-244"><a href="#cb12-244" aria-hidden="true" tabindex="-1"></a><span class="fu">### Filters can deteriorate</span></span>
<span id="cb12-245"><a href="#cb12-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-246"><a href="#cb12-246" aria-hidden="true" tabindex="-1"></a>Some types of ionic glass filters have high concentrations of metal salts in their composition and their surface can oxidise in contact with humid air. If they have antireflection, or other coatings or thin layers deposited on their surface they tend be well protected. Those, with no coatings, can need especially in wet climates to be polished using fine cerium oxide paste or restored chemically. The recommendation is to store filters in a dry place and to regularly inspect the condition of their surface.</span>
<span id="cb12-247"><a href="#cb12-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-248"><a href="#cb12-248" aria-hidden="true" tabindex="-1"></a>The spectral transmittance of both clear plastic and glass can change on exposure to strong light, specially blue and shorter wavelengths. In the case of plastics, not only cellulose acetate is affected. Of glasses, those containing iron, usually as an impurity, are the most prone to "yellowing" through "solarization".</span>
<span id="cb12-249"><a href="#cb12-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-250"><a href="#cb12-250" aria-hidden="true" tabindex="-1"></a>Scratches on the coatings or the glass surface, if small and superficial, tend to affect image quality mainly through reflections generating haze and sometimes small ghosts. Small scratches themselves are in most situations completely out of focus and invisible. The wider the aperture, the less likely they are to show in the images.</span>
<span id="cb12-251"><a href="#cb12-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-252"><a href="#cb12-252" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-253"><a href="#cb12-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-254"><a href="#cb12-254" aria-hidden="true" tabindex="-1"></a>**Plastic filters** are sometimes used for photography, specially at relatively large sizes like $50 \times 50$ mm or $100 \times 100$ mm squares 2 or 3 mm-thick, as they are cheaper than glass. They can be easily damaged in ways that can affect the quality of images, and need to be handled carefully. On the other hand, small scratches are irrelevant when filters are used on light sources, but in this case it is necessary to protect them from excessive heat. On light sources of many kinds it is common to use coloured plastic films or "theatrical gels" rather than thicker materials.</span>
<span id="cb12-255"><a href="#cb12-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-256"><a href="#cb12-256" aria-hidden="true" tabindex="-1"></a>Until approximately 50 years ago **gelatine filters** were common. Obviously a thin layer of dry coloured gelatine is extremely fragile, but because they are so thin affect an optical system much less than thicker filters. They are still used, especially for filters located between the back of a lens and the sensor or film. When a thicker glass filter is located between sensor or film and objective, the focus point shifts, in extreme cases restricting the focusing range of the objective.</span>
<span id="cb12-257"><a href="#cb12-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-258"><a href="#cb12-258" aria-hidden="true" tabindex="-1"></a>There is an additional type of absorptive filters, formely very common in photography: a thin light-absorbing layer of coloured **gelatine encased between two layers of optical glass**. As far as I know, only <span class="co">[</span><span class="ot">Tiffen</span><span class="co">](https://tiffen.com)</span> still makes filters of this kind (@fig-img-filters-tiffen-haze).</span>
<span id="cb12-259"><a href="#cb12-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-262"><a href="#cb12-262" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-263"><a href="#cb12-263" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-img-filters-tiffen-haze</span></span>
<span id="cb12-264"><a href="#cb12-264" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.5</span></span>
<span id="cb12-265"><a href="#cb12-265" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-266"><a href="#cb12-266" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Total transmittance spectra of a filter made as an film encased</span></span>
<span id="cb12-267"><a href="#cb12-267" aria-hidden="true" tabindex="-1"></a><span class="co">#|   between two glass layers. A UV-blocking filter, or "haze" filter</span></span>
<span id="cb12-268"><a href="#cb12-268" aria-hidden="true" tabindex="-1"></a><span class="co">#|   (type 2A from Tiffen).  </span></span>
<span id="cb12-269"><a href="#cb12-269" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-270"><a href="#cb12-270" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">convertTfrType</span>(filters.mspct<span class="sc">$</span>Tiffen_Haze_2A_2<span class="fl">.6</span>mm_52mm,</span>
<span id="cb12-271"><a href="#cb12-271" aria-hidden="true" tabindex="-1"></a>                        <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb12-272"><a href="#cb12-272" aria-hidden="true" tabindex="-1"></a>                        <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>))</span>
<span id="cb12-273"><a href="#cb12-273" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-274"><a href="#cb12-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-275"><a href="#cb12-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-276"><a href="#cb12-276" aria-hidden="true" tabindex="-1"></a>**Interference filters** work by reflection from surface multilayer thin coatings. As with reflection in general, reflectance by the thin layers is affected by the light incidence angle. In this type of filters the cut-off and cut-in wavelengths shift significantly at shallow light incidence angles compared to normal incidence. Their main advantage is that they can be designed to have very sharp cut-in and cut-offs, can have multiple discontinuous trtansmission bands and very strong blocking of off-band radiation (@fig-img-filters-uvcut-interference). They are available with transmitted bands as narrow as a couple of nm to 100's of nanometres. However, only the best and most expensive interference filters achieve such high performance. The better filters have more thin-layers with more accurate thickness, which increases the fabrication cost. As they are usually deposited on optical-grade quartz as subtrate, the thikness of the substrate of these filters has little if any effect on their spectral properties. The thin films are fragile, so some of these filters have a hard-coating added at their surface for protection. In spite of working by reflection, which face of the filter points to the light source does not significantly affect their spectral transmittance. Some of these filters have coatings on only one surface, while other can have different coatings on their two surfaces. It is important to remember here that reflections take place at each interface between media of different refractive indexes.</span>
<span id="cb12-277"><a href="#cb12-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-280"><a href="#cb12-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-281"><a href="#cb12-281" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-img-filters-uvcut-interference</span></span>
<span id="cb12-282"><a href="#cb12-282" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.90</span></span>
<span id="cb12-283"><a href="#cb12-283" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-284"><a href="#cb12-284" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Total transmittance spectra of two dichroic or interference</span></span>
<span id="cb12-285"><a href="#cb12-285" aria-hidden="true" tabindex="-1"></a><span class="co">#|   filters, one UV-blocking (Zeiss UV T*) and one UV and IR-blocking</span></span>
<span id="cb12-286"><a href="#cb12-286" aria-hidden="true" tabindex="-1"></a><span class="co">#|   (Firecrest UVIR cut). Both filters are in addition antireflection</span></span>
<span id="cb12-287"><a href="#cb12-287" aria-hidden="true" tabindex="-1"></a><span class="co">#|   multicoated.</span></span>
<span id="cb12-288"><a href="#cb12-288" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-289"><a href="#cb12-289" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(</span>
<span id="cb12-290"><a href="#cb12-290" aria-hidden="true" tabindex="-1"></a>    <span class="fu">convertTfrType</span>(</span>
<span id="cb12-291"><a href="#cb12-291" aria-hidden="true" tabindex="-1"></a>      filters.mspct[<span class="fu">c</span>(<span class="st">"Zeiss_UV_Tstar_2.0mm_52mm"</span>, </span>
<span id="cb12-292"><a href="#cb12-292" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Firecrest_UVIR_Cut_0.96mm_52mm"</span>)],</span>
<span id="cb12-293"><a href="#cb12-293" aria-hidden="true" tabindex="-1"></a>      <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb12-294"><a href="#cb12-294" aria-hidden="true" tabindex="-1"></a>    <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb12-295"><a href="#cb12-295" aria-hidden="true" tabindex="-1"></a>    <span class="at">facets =</span> <span class="dv">1</span>)</span>
<span id="cb12-296"><a href="#cb12-296" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-297"><a href="#cb12-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-298"><a href="#cb12-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-299"><a href="#cb12-299" aria-hidden="true" tabindex="-1"></a>Some of the best VIS-blocking UV-pass filters for photography and astronomy ("Venus filters") are interference filters with VIS-absorbing ionic glass as substrate. Some of them, even have different interference filters deposited on each of their faces. The added interference filter coatings blocks the IR "leaks" that the ionic glass has (@fig-img-filters-uv-pass). Some photographers argue that which face of these filters faces the sensor can affect reflections within the camera resulting slightly different amounts of glare. Of the ordinary filters used in VIS photography, only some UV-blocking filters, some neutral density filters and all UV + NIR blocking filters are interference filters, most other filters are absprptive.</span>
<span id="cb12-300"><a href="#cb12-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-303"><a href="#cb12-303" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-304"><a href="#cb12-304" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-img-filters-uv-pass</span></span>
<span id="cb12-305"><a href="#cb12-305" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.90</span></span>
<span id="cb12-306"><a href="#cb12-306" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-307"><a href="#cb12-307" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Total transmittance spectra of two short-pass UV filters, one </span></span>
<span id="cb12-308"><a href="#cb12-308" aria-hidden="true" tabindex="-1"></a><span class="co">#|   an dichroic or interference filters on a 1 mm-thick Schott UG11</span></span>
<span id="cb12-309"><a href="#cb12-309" aria-hidden="true" tabindex="-1"></a><span class="co">#|   ionic glass substrate (Bader Venus-U), and the other a plain </span></span>
<span id="cb12-310"><a href="#cb12-310" aria-hidden="true" tabindex="-1"></a><span class="co">#|   2 mm-thick UG11 ionic glass filter</span></span>
<span id="cb12-311"><a href="#cb12-311" aria-hidden="true" tabindex="-1"></a><span class="co">#|   (Firecrest UVIR cut). Both filters are in addition antireflection</span></span>
<span id="cb12-312"><a href="#cb12-312" aria-hidden="true" tabindex="-1"></a><span class="co">#|   multicoated.</span></span>
<span id="cb12-313"><a href="#cb12-313" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-314"><a href="#cb12-314" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(</span>
<span id="cb12-315"><a href="#cb12-315" aria-hidden="true" tabindex="-1"></a>    <span class="fu">convertTfrType</span>(</span>
<span id="cb12-316"><a href="#cb12-316" aria-hidden="true" tabindex="-1"></a>      filters.mspct[<span class="fu">c</span>(<span class="st">"Baader_U_filter_1.0mm_48mm"</span>, </span>
<span id="cb12-317"><a href="#cb12-317" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Schott_UG11"</span>)],</span>
<span id="cb12-318"><a href="#cb12-318" aria-hidden="true" tabindex="-1"></a>      <span class="at">Tfr.type =</span> <span class="st">"total"</span>), </span>
<span id="cb12-319"><a href="#cb12-319" aria-hidden="true" tabindex="-1"></a>    <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb12-320"><a href="#cb12-320" aria-hidden="true" tabindex="-1"></a>    <span class="at">facets =</span> <span class="dv">1</span>)</span>
<span id="cb12-321"><a href="#cb12-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-322"><a href="#cb12-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-323"><a href="#cb12-323" aria-hidden="true" tabindex="-1"></a>Each glass-air interface reflects approximately 4.5% of the light traversing it as result of the difference in refractive index ($n$). Modern lenses and good photographic filters are **anti-reflection multicoated**, and the best ones reflect $&lt; 0.1\%$ of the light impinging on their surface. These coatings are similar in principle to interference filters, they change $n$ at the surface. However, they are designed to minimize reflections across a given range of wavelengths instead of increeasing them. In recent years a further additional coating is being applied to outer lens surfaces and filters, a fluorine compound coating that alters surface properties so that water runs off the surface and dirt does not stick. Antireflection coatings do modify the spectral transmittance, increasing it in the target range of wavelengths but frequently decreasing it in other regions of the spectrum. </span>
<span id="cb12-324"><a href="#cb12-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-325"><a href="#cb12-325" aria-hidden="true" tabindex="-1"></a><span class="fu">## UV, VIS and NIR radiation sources</span></span>
<span id="cb12-326"><a href="#cb12-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-327"><a href="#cb12-327" aria-hidden="true" tabindex="-1"></a>As in many applications, LEDs have replaced incandescent lamps as light sources for VIS photography, while Xenon-arc flashes remain popular. The spectrum of white light sources based on LEDs used in photography has improved in recent years. The suitability of white LED light is rated based on indexes, of which the most frequently reported is the colour rendition index (CRI), expressed in a scale from 0 to 100. In practice, good colour reproduction in photographs requires CRI &gt;= 95 (@fig-imge-white-leds-cri). Most white LEDs used in households, public spaces and growth chambers have CRI &lt;&lt; 90 and sometimes CRI &lt; 80. This should be taken into consideration when photographs are used to record the outcome of experiemnts.</span>
<span id="cb12-328"><a href="#cb12-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-331"><a href="#cb12-331" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-332"><a href="#cb12-332" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-imge-white-leds-cri</span></span>
<span id="cb12-333"><a href="#cb12-333" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 1.5</span></span>
<span id="cb12-334"><a href="#cb12-334" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-335"><a href="#cb12-335" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Emission spectra of four white LED of different types, two with high CRI (Sunlike, from Seoul Semicon and Optisolis from Nichia) and two with lower CRI (an older Nichia LED and a modern LED for horticulture from Luminus).</span></span>
<span id="cb12-336"><a href="#cb12-336" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-337"><a href="#cb12-337" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(leds.mspct[<span class="fu">c</span>(<span class="st">"SeoulSemicon_S4SM_1564509736_0B500H3S_00001"</span>,</span>
<span id="cb12-338"><a href="#cb12-338" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Nichia_NFCWL036B_V3_Rfcb0"</span>, </span>
<span id="cb12-339"><a href="#cb12-339" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"Nichia_unknown_757"</span>,</span>
<span id="cb12-340"><a href="#cb12-340" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"Luminus_CXM_14_HS_12_36_AC30"</span>)],</span>
<span id="cb12-341"><a href="#cb12-341" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb12-342"><a href="#cb12-342" aria-hidden="true" tabindex="-1"></a>         <span class="at">facets =</span> <span class="dv">1</span>)</span>
<span id="cb12-343"><a href="#cb12-343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-344"><a href="#cb12-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-345"><a href="#cb12-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-346"><a href="#cb12-346" aria-hidden="true" tabindex="-1"></a>Daylight is a good source of UV-A1 radiation during most of the day. When the sun is more than 30 or 40 degrees above the horizon UV-A1, UV-A2 and UV-B are usualy enough for photograpying still subjects. The irradiance of NIR compared to VIS in daylight varies less than that of UV-B and UV-A. As described in Chapter XX, the scattering of sunlight in the atmosphere is more at shorter than at longer wavelengths. Lanscapes look very different in a UV and in a NIR image. The proportion of UV-A in the shade can be high but the low irradiance makes very long exposures necessary. When using "accidental" UV objectives their rather low transmittance compounded with a decreased sensor sensitivity at short wavelength usually makes UV photography in natural light challenging because of long exposure times.  </span>
<span id="cb12-347"><a href="#cb12-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-348"><a href="#cb12-348" aria-hidden="true" tabindex="-1"></a>Xenon flash lamps emit as much or more UV-A radiation than VIS light, but those sold for VIS photography are in most cases filtered so as to block all UV to make their use safer and to avoid a blue cast in photographs. A Xenon flash arc inherently emits across the whole UV-A, UV-B and UV-C, VIS, and NIR regions. However, depending on the glass or quartz lamp envelope, the shorter wavelengths may not exit the lamp. However, even Xenon flash lamps with a glass envelope emit UV-A radiation. The spectrum even if full of features (peaks and valleys), is rather continuous (@fig-img-xe-flash).</span>
<span id="cb12-349"><a href="#cb12-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-352"><a href="#cb12-352" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-353"><a href="#cb12-353" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-img-xe-flash</span></span>
<span id="cb12-354"><a href="#cb12-354" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.90</span></span>
<span id="cb12-355"><a href="#cb12-355" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-356"><a href="#cb12-356" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Emission spectra of two different "heads" on the same Xenon flash</span></span>
<span id="cb12-357"><a href="#cb12-357" aria-hidden="true" tabindex="-1"></a><span class="co">#|   (Godox AD200) one original and filtered to block all UV radiation </span></span>
<span id="cb12-358"><a href="#cb12-358" aria-hidden="true" tabindex="-1"></a><span class="co">#|   and one with quartz flash tube, not filtered, from a different</span></span>
<span id="cb12-359"><a href="#cb12-359" aria-hidden="true" tabindex="-1"></a><span class="co">#|   supplier (FTSTS40W quartz Xenon lamp on a Godox H200j bare-lamp</span></span>
<span id="cb12-360"><a href="#cb12-360" aria-hidden="true" tabindex="-1"></a><span class="co">#|   flash head).</span></span>
<span id="cb12-361"><a href="#cb12-361" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-362"><a href="#cb12-362" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(lamps.mspct[<span class="fu">c</span>(<span class="st">"Godox.XeF.AD200.H200j.FTSTS40w.flash"</span>, </span>
<span id="cb12-363"><a href="#cb12-363" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"Godox.XeF.AD200.H200.flash"</span>)],</span>
<span id="cb12-364"><a href="#cb12-364" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb12-365"><a href="#cb12-365" aria-hidden="true" tabindex="-1"></a>         <span class="at">facets =</span> <span class="dv">1</span>)</span>
<span id="cb12-366"><a href="#cb12-366" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-367"><a href="#cb12-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-368"><a href="#cb12-368" aria-hidden="true" tabindex="-1"></a>Radiation from Xenon flashes, similarly to sunlight, can produce false-colour UV and NIR images. This is true, even if filtered to block UV-B and UV-C for safety. UV-B and UV-C wavelengths are blocked by "accidental" UV objectives and anyway not detected by digital sensors even in full-spectrum modified cameras.</span>
<span id="cb12-369"><a href="#cb12-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-370"><a href="#cb12-370" aria-hidden="true" tabindex="-1"></a>LEDs with peaks of emission between 365 nm and 415 nm do emit UV-A1 and are cheap and readily available. However, because of their rather narrow peaks of emission (@fig-img-leds-uva) they create nearly monochromatic images, with little false colour, when used singly. One possibility is to use an array with a mix of LEDs emitting at different but partly overlapping UV-A wavelengths.</span>
<span id="cb12-371"><a href="#cb12-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-374"><a href="#cb12-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-375"><a href="#cb12-375" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-img-leds-uva</span></span>
<span id="cb12-376"><a href="#cb12-376" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.90</span></span>
<span id="cb12-377"><a href="#cb12-377" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: &gt;</span></span>
<span id="cb12-378"><a href="#cb12-378" aria-hidden="true" tabindex="-1"></a><span class="co">#|   Emission spectra of two 4W UV-A1 LEDs (types LZ1-10UV00 and </span></span>
<span id="cb12-379"><a href="#cb12-379" aria-hidden="true" tabindex="-1"></a><span class="co">#|   LZ1-10UB00-00U4 from Led Engin-Osram).</span></span>
<span id="cb12-380"><a href="#cb12-380" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb12-381"><a href="#cb12-381" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(leds.mspct[<span class="fu">c</span>(<span class="st">"LedEngin_LZ1_10UV00_365nm"</span>,</span>
<span id="cb12-382"><a href="#cb12-382" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"LedEngin_LZ1_10UB00_00U4_385nm"</span>)],</span>
<span id="cb12-383"><a href="#cb12-383" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">250</span>, <span class="dv">900</span>), </span>
<span id="cb12-384"><a href="#cb12-384" aria-hidden="true" tabindex="-1"></a>         <span class="at">facets =</span> <span class="dv">1</span>)</span>
<span id="cb12-385"><a href="#cb12-385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-386"><a href="#cb12-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-387"><a href="#cb12-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-388"><a href="#cb12-388" aria-hidden="true" tabindex="-1"></a>In the case of NIR all three sources are effective: sunlight, Xenon flash and LEDs. This is helped by the high native sensitivity of Si-based image sensors in this region of the spectrum. LEDs with their narrow peaks of emission unless combined, fail to produce strong false colour effects. Because of the properties of the red, green and blue filters on pixels of camera sensors, the false colour originates mostly from R and FR wavelengths $\lambda &lt; 850 \mathrm{nm}$.</span>
<span id="cb12-389"><a href="#cb12-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-390"><a href="#cb12-390" aria-hidden="true" tabindex="-1"></a>::: callout-caution</span>
<span id="cb12-391"><a href="#cb12-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-392"><a href="#cb12-392" aria-hidden="true" tabindex="-1"></a><span class="fu">### Illumination flicker</span></span>
<span id="cb12-393"><a href="#cb12-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-394"><a href="#cb12-394" aria-hidden="true" tabindex="-1"></a>Many light sources including all incandescent lamps and many gas-discharge- and LED lamps, flicker at twice the frequency of the AC power line. The AC line frequency, 50 Hz or 60 Hz, has most likely been chosen so that the light fkicker is not noticeable to human vision. Modern electronic ballasts for gas-discharge lamps and drivers for LEDs tend to use higher frequencies, anywhere between 300 Hz and a few kHz. However, two contrasting approaches to LED dimming are in use. Some LED drivers use a constant-current approach to dimming, and avoid flicker completly. Meanwhile other drivers use the pulse-width-modulation approach (PWM) to dimming, that consist in switching the LEDs on and off at a usually fast frequency. Old-style mains dimmers generate strong flicker at line frequency.</span>
<span id="cb12-395"><a href="#cb12-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-396"><a href="#cb12-396" aria-hidden="true" tabindex="-1"></a>Flicker and the more drastic PWM dimming need to be taken into account when selecting the shutter speed used. At fast shutter speeds (= short exposure times), both in film and in most digital cameras, there is a small difference in time when different parts of an image are acquired. Under light flickering in brightness, banding in images apears as subtke differences in exposure. In the case of PWM diming banding can is some cases apears as black unexposed bands. In the case of colour-mixing LEDs based on PWM the bands can be of multiple colors.</span>
<span id="cb12-397"><a href="#cb12-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-398"><a href="#cb12-398" aria-hidden="true" tabindex="-1"></a>The general solution to this problem is to use a suficiently long exposure time, and when possible ensure that the exposure time is such that includes a whole number of flicker cycles. When flicker is synchronized to the AC power line frequency, the frequency is known and the exposure time can be selected accordingly. For example, in Europe this frequency is 50 Hz and the flicker frequency 100 Hz, so using an exposure time of 1/50 s is preferable to using 1/60 s. With modern LED drivers there is no known frequency, and even the frequency and phase of the flicker from different luminaires can differ. Unless the camera being used can detect the frequncy and automatically tweak exposure times, the good and bad exposure times can be learnt by trial an error. There is a further possibility, if the sensor readout time is known, the frequency of the flicker can be estimated from the banding recorded in an image.</span>
<span id="cb12-399"><a href="#cb12-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-400"><a href="#cb12-400" aria-hidden="true" tabindex="-1"></a>LED light sources sold for photography and video, in general use CC dimming or alternatively PWM dimming at a high frequency. The flicker in the later is noticeable only in images acquired using very fast shutter speeds.</span>
<span id="cb12-401"><a href="#cb12-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-402"><a href="#cb12-402" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-403"><a href="#cb12-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-404"><a href="#cb12-404" aria-hidden="true" tabindex="-1"></a><span class="fu">## Accessories</span></span>
<span id="cb12-405"><a href="#cb12-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-406"><a href="#cb12-406" aria-hidden="true" tabindex="-1"></a><span class="fu">### Colour and grey-scale references</span></span>
<span id="cb12-407"><a href="#cb12-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-408"><a href="#cb12-408" aria-hidden="true" tabindex="-1"></a>White, black and grey references have two main uses. One is to optimally and consistently set exposure independently of the reflectance of the subject of the photograph. The second, and more familiar use, is to set the white balance on a light grey or white reference, so that it describes the light source idependently of the subject photographed. If included in images, white balance can be adjusted objectively also in post-processing. With set of grey patches it becomes feasible, although not easy, to compensate differences in in-camera exposure in post-processing. Although, a single grey reference of 18% reflectance helps in the overall adjustments of exposure, it does not provide enough information to compensate for differences in the steepness of the response curve and dynamic range among images. These properties images are affected by exposure and ISO settings.</span>
<span id="cb12-409"><a href="#cb12-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-410"><a href="#cb12-410" aria-hidden="true" tabindex="-1"></a>Colour "checkers" with tiles of different colours with known spectral reflectance are routinely used in photography that requires faithful colour reproduction, e.g., commercial photography. They are available with different numbers of tiles, the more tiles the more colours that can be calibrated and corrected. The most comon colour checkers have 24 tiles, xx colours plus a gradation greys from white to black. They come in different sizes, small ones suitable for macro photography and several larger sizes. These easily available references cover only visible colours, i.e., those recorded by "normal" cameras. There exist reference tiles for UV and NIR, but they are extremely expensive.</span>
<span id="cb12-411"><a href="#cb12-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-412"><a href="#cb12-412" aria-hidden="true" tabindex="-1"></a>The best approach is to use them to generate a custom colour profile for a given combination of light source, camera, objective and filter. However, the "colour cast" introduced by objectives and UV-cut or UVIR-cut filters is usually rather small. </span>
<span id="cb12-413"><a href="#cb12-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-414"><a href="#cb12-414" aria-hidden="true" tabindex="-1"></a>A colour profile is constructed by photographying the colour target and loading the resulting image into software that analyses it and compares the pixel values to those expected for each tile. The procedure optimizes the multiplers to apply to the the R, G and B raw values from the camera sensor to convert them as close as possible to the expected values for each colour tile. The procedure also makes use of the black, white and grey tiles to adjust the response to luminosity. Some RAW file converters also support the creating of colour profiles. There are also computer programs for the construction of colour profiles.</span>
<span id="cb12-415"><a href="#cb12-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-416"><a href="#cb12-416" aria-hidden="true" tabindex="-1"></a>The calibration procedure needed to obtain "true" colours consistently through time or across sites depends on colour references with accurately known spectral properties that are of high quality and have been recently acquired (because they age). In such a case we can assume that different colour targets from the same manufacturer and type are nearly identical and comparable. However, if we only aim to achieve good colour consistency across a single set of images together with imperfect but reasonably good colour reproduction, it is enough to use the same colour target as reference for all the images to be compared. Thus an older colour target or one with weaker specifications can reduce the expenses.</span>
<span id="cb12-417"><a href="#cb12-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-418"><a href="#cb12-418" aria-hidden="true" tabindex="-1"></a>In general, the lower the CRI rating of a light source, the more necessary it is to use a custom colour profile. When assessing illumination, reflected light must be considered. For example, a LED lamp with very high CRI rating is used in a room with walls painted in a bright colour, the spectrum of the light effectively illuminating the object photographed most likely will differ in its spectrum from that emitted by the lamp.</span>
<span id="cb12-419"><a href="#cb12-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-420"><a href="#cb12-420" aria-hidden="true" tabindex="-1"></a>Of all situations, the most challenging is when the light illuminating different parts of the object photographed differs in colour (= spectrum). Lamps used in household and commercial illumination have in most cases CRI &lt;= 85, and are also available with different colour-temperature ratings. Quite frequently, lamps that have been installed at different times differ in emission spectra, even within a given colour temperature and lamp brand. An more dramatic case is a mix of warmer artificial light and cooler daylight entering through windows. Whenever possible, strive to acquire images under light with a homogenous spectrum.</span>
<span id="cb12-421"><a href="#cb12-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-422"><a href="#cb12-422" aria-hidden="true" tabindex="-1"></a><span class="fu">## Procedures</span></span>
<span id="cb12-423"><a href="#cb12-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-424"><a href="#cb12-424" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reproducibility</span></span>
<span id="cb12-425"><a href="#cb12-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-426"><a href="#cb12-426" aria-hidden="true" tabindex="-1"></a>When used in research, imaging can be done for illustration purposes or as an approach to quantitative measurement. In the second case, reproducibility plays a crucial role towards correct quantification, while in the first case it is important to avoid misleading the viewers of the illustrations. In some fields, illustrative photographs are used as scientific evidence, thus, avoiding bias is also crucial even no quantification is done. Bias can be introduced both when the image is captured and during image post-processing.</span>
<span id="cb12-427"><a href="#cb12-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-428"><a href="#cb12-428" aria-hidden="true" tabindex="-1"></a>Comparable images can be obtained by keeping illumination, image acquisition and post-processing perfectly consistent. When there is relatively small variation in illumination or camera response, the use of colour and grey references can allow corrections to partly remove bias. References within images can also serve as a built-in quality control. When the colours need to closely match the object photographed the use of "a colour managed workflow" is required. In such a workflow colur calibrations are used at each stage, and at each step loss of information is avoided. For example, a white light source deficient in violet or green light makes correctly recording those colours impossible. It is important to remember that digital photographics cameras, do not sense colours as narrow wavelength bands, but instead reconstruct the colours we see, discarding a lot of information. This makes the colour bias caused by illumination with a low CRI light source difficult to fully correct after the fact.</span>
<span id="cb12-429"><a href="#cb12-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-430"><a href="#cb12-430" aria-hidden="true" tabindex="-1"></a>Most digital cameras set exposure automatically. However, when consistency is important, exposure must be set using a grey reference card (18% reflectance) either manually or the automatically found setting locked. Otherwise, the auto-exposure algorithm will compensate at least in part for the differences in luminance between objects, for example small vs. large plants on a dark or light background, or between dark and pale plants. If we are only interested in the shape of the plants, size, etc., some amount of bias can be tolerated. In contrast if reflectance or spectral reflectance (darkness or colour) are relevant, consistent exposure is crucial.</span>
<span id="cb12-431"><a href="#cb12-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-432"><a href="#cb12-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-433"><a href="#cb12-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-434"><a href="#cb12-434" aria-hidden="true" tabindex="-1"></a><span class="fu">### UV photography</span></span>
<span id="cb12-435"><a href="#cb12-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-436"><a href="#cb12-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### NIR photography</span></span>
<span id="cb12-437"><a href="#cb12-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-438"><a href="#cb12-438" aria-hidden="true" tabindex="-1"></a><span class="fu">### UVIVF</span></span>
<span id="cb12-439"><a href="#cb12-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-440"><a href="#cb12-440" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Camera: It is best to use a digital mirrorless (ML) camera. An off-the-shelf</span>
<span id="cb12-441"><a href="#cb12-441" aria-hidden="true" tabindex="-1"></a>camera is the best tool unless NIR fluorescence is of interest.</span>
<span id="cb12-442"><a href="#cb12-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-443"><a href="#cb12-443" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Objective: Most lenses work well but given the very low light levels a lens with an f/2.8 apperture or wider is preferable.</span>
<span id="cb12-444"><a href="#cb12-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-445"><a href="#cb12-445" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Light source: A 365 nm LED-based flashlight works well if of enough power</span>
<span id="cb12-446"><a href="#cb12-446" aria-hidden="true" tabindex="-1"></a>(&gt;= 3 W for a 0.25 m to 2.0 m range and static subjects), preferably with a Nichia LED and an VIS-blocking filter such as 3 mm or 2 mm-thick SWB2 filter. The induced fluorescence is weak so that if any visible light emitted by the UV source can go through both filters, it will show in the photographs.</span>
<span id="cb12-447"><a href="#cb12-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-450"><a href="#cb12-450" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-451"><a href="#cb12-451" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">smooth_spct</span>(lamps.mspct[<span class="fu">c</span>(<span class="st">"Convoy.S2plus.LED.UVA.flashlight"</span>)], </span>
<span id="cb12-452"><a href="#cb12-452" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method =</span> <span class="st">"supsmu"</span>, <span class="at">strength =</span> <span class="fl">0.001</span>),</span>
<span id="cb12-453"><a href="#cb12-453" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>))</span>
<span id="cb12-454"><a href="#cb12-454" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-455"><a href="#cb12-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-456"><a href="#cb12-456" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>On-camera filter: A high-quality UV-blocking filter is needed. Most UV-filters</span>
<span id="cb12-457"><a href="#cb12-457" aria-hidden="true" tabindex="-1"></a>sold for photography have a cut-in at too short wavelengths (330 to 380 nm). However, when using a 365 nm LED as light source the filter used on the lens has to block wavelengths just past 400 nm. The best, but rather expensive, option is a Zeiss UV T* filter, second best is a significantly cheaper Firecrest UV400 filter (from Formatt-Hitech, apparently gone bankrupt), and a third option is a Tiffen Haze 2A filter (rather difficult to find outside USA). The first two are interference filters and reflect UV, rather than absorb it. The Tiffen filter, a rather old type in the tradition of Kodak Wratten filters, has a thin UV-absorbing gelatine layer encased between two glass sheets. None of these three filters fluoresce significantly when exposed to UV radiation. Most yellow, orange and red filters are made of ionic glass and when illuminated with UV fluoresce strongly. They can be used only behind a UV-absorbing filter. NIR pass filters are also ionic and do also fluoresce, but less intensively (I am not sure of which wavelengths induce the strongest fluorescence in NIR filters, but likely from the VIS range).</span>
<span id="cb12-458"><a href="#cb12-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-461"><a href="#cb12-461" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-462"><a href="#cb12-462" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(filters.mspct[<span class="fu">c</span>(<span class="st">"Zeiss_UV_Tstar_2.0mm_52mm"</span>,</span>
<span id="cb12-463"><a href="#cb12-463" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Hoya_UV0_HMC_2.0mm_52mm"</span>)],</span>
<span id="cb12-464"><a href="#cb12-464" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>)) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>) </span>
<span id="cb12-465"><a href="#cb12-465" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-466"><a href="#cb12-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-469"><a href="#cb12-469" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-470"><a href="#cb12-470" aria-hidden="true" tabindex="-1"></a>(<span class="fu">autoplot</span>(<span class="fu">smooth_spct</span>(<span class="fu">normalise</span>(lamps.mspct[[<span class="st">"Convoy.S2plus.LED.UVA.flashlight"</span>]], <span class="at">norm =</span> <span class="st">"undo"</span>) <span class="sc">*</span></span>
<span id="cb12-471"><a href="#cb12-471" aria-hidden="true" tabindex="-1"></a>                       filters.mspct[[<span class="st">"Zeiss_UV_Tstar_2.0mm_52mm"</span>]], <span class="at">method =</span> <span class="st">"supsmu"</span>, <span class="at">strength =</span> <span class="fl">0.5</span>),</span>
<span id="cb12-472"><a href="#cb12-472" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="fl">6.2</span>), </span>
<span id="cb12-473"><a href="#cb12-473" aria-hidden="true" tabindex="-1"></a>         <span class="at">annotations =</span> <span class="fu">c</span>(<span class="st">"-"</span>, <span class="st">"peaks"</span>)) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"Zeiss UV T* filter"</span>) <span class="sc">+</span></span>
<span id="cb12-474"><a href="#cb12-474" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)) <span class="sc">|</span></span>
<span id="cb12-475"><a href="#cb12-475" aria-hidden="true" tabindex="-1"></a>(<span class="fu">autoplot</span>(<span class="fu">smooth_spct</span>(<span class="fu">normalise</span>(lamps.mspct[[<span class="st">"Convoy.S2plus.LED.UVA.flashlight"</span>]], <span class="at">norm =</span> <span class="st">"undo"</span>) <span class="sc">*</span></span>
<span id="cb12-476"><a href="#cb12-476" aria-hidden="true" tabindex="-1"></a>                       filters.mspct[[<span class="st">"Hoya_UV0_HMC_2.0mm_52mm"</span>]], <span class="at">method =</span> <span class="st">"supsmu"</span>, <span class="at">strength =</span> <span class="fl">0.5</span>),</span>
<span id="cb12-477"><a href="#cb12-477" aria-hidden="true" tabindex="-1"></a>         <span class="at">range =</span> <span class="fu">c</span>(<span class="dv">315</span>, <span class="dv">450</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="fl">6.2</span>), </span>
<span id="cb12-478"><a href="#cb12-478" aria-hidden="true" tabindex="-1"></a>         <span class="at">annotations =</span> <span class="fu">c</span>(<span class="st">"-"</span>, <span class="st">"peaks"</span>)) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"Hoya UV(0) filter"</span>) <span class="sc">+</span> </span>
<span id="cb12-479"><a href="#cb12-479" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)) <span class="sc">+</span> <span class="fu">plot_layout</span>(<span class="at">axis_titles =</span> <span class="st">"collect"</span>)</span>
<span id="cb12-480"><a href="#cb12-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-481"><a href="#cb12-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-482"><a href="#cb12-482" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb12-483"><a href="#cb12-483" aria-hidden="true" tabindex="-1"></a><span class="fu"># UV-induced fluorescence of filters</span></span>
<span id="cb12-484"><a href="#cb12-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-485"><a href="#cb12-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-486"><a href="#cb12-486" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-487"><a href="#cb12-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-488"><a href="#cb12-488" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Support: Exposure times between 20 s and a 2 min are common, so the camera must be mounted so that it cannot move. I normally use a tripod outdoors and a copy stand or a tripod indoors. Many modern camera can be controlled with a phone app, while older ones can be triggered with a cable or radio-remote. If a IR remote is to be used, better test that its light does not show in the photographs.</span>
<span id="cb12-489"><a href="#cb12-489" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Location, outdoors: The best location is far from any artificial illumination in a moon-less night. How dark it needs to be depends on the length of expossure, so brightly fluorescing subjects like some lichens are more forgiving. At high latitudes, in the late spring and summer, it remains too bright through out the night. The autumun is the best season, especially if one gets a windless night.</span>
<span id="cb12-490"><a href="#cb12-490" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Location, indoors: Even in a dark room, there are usually items that strongly fluoresce such as light-coloured clothing, white papers and even some plastics. One needs to move such items away and if not possible, set the UV-radiation beam to illuminate the subject but not those items. </span>
<span id="cb12-491"><a href="#cb12-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-492"><a href="#cb12-492" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb12-493"><a href="#cb12-493" aria-hidden="true" tabindex="-1"></a><span class="fu"># Tools I use</span></span>
<span id="cb12-494"><a href="#cb12-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-495"><a href="#cb12-495" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Camera: mirrorless digital cameras. Since three years ago Olympus OM-1, five years ago an Olympus E-M1 Mk II and about 10 years ago an Olympus E-M1. The OM-1 has a feature that is especially good for very long exposures: it can display the image while it is being captured, even on the screen of a phone or tablet. Used with the shutter in _bulb_ mode one can close the shutter when the image looks bright enough. In addition, one can see live how light painting with the flashlight affects the image.</span>
<span id="cb12-496"><a href="#cb12-496" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Objectives: I have used for many years most frequently a Sigma 30 mm f/1.4, and more recently an M.Zuiko 25 mm f/1.2 in its place. When needing other focal lengths the M.Zuiko 12-40 mm f/2.8 zoom has worked well. After all, one is just photographing VIS light, so almost any lens should work nicely optically.</span>
<span id="cb12-497"><a href="#cb12-497" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>On camera filter: the three mentioned above, interchangeably. Sometimes combined with long-pass filters.</span>
<span id="cb12-498"><a href="#cb12-498" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Flashlight UVA: Convoy 2+ with 365 nm Nichia LED rated at 3 W. I replaced the clear window with a VIS-blocking filter. This flashlight has a narrow and very intense UV beam that works very well for light painting. Jaxman 1aC 365 nm 6W "flood" flashlight has a broader and less intense UV beam. It came already with a VIS-blocking filter installed. The two flashlight are physically very similar but differ in the LED and most significantly the reflector.</span>
<span id="cb12-499"><a href="#cb12-499" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Flashlight, VIS: As I tend to take a paired reference photograph in white light for each fluorescence image, I use a 5W video fill light (SunwayFoto FL96). Many similar lamps are avaialble, but not all of them have a high colour rendition index (CRI). A value of 95 or higher is good for colour reproduction.</span>
<span id="cb12-500"><a href="#cb12-500" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>White reference slab: A normal colour chart is unsuitable. Some grey cards sold for white balancing can be used but I consider them too expensive to use in the field, especially in the dark. I use instead a piece a white "vigin" (not recycled) PTFE (=Teflon) about 6 mm thick. _Pure clean_ PTFE has similar and very high reflectance in the UV, VIS and NIR, and can be easily washed to clean it.</span>
<span id="cb12-501"><a href="#cb12-501" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-502"><a href="#cb12-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-503"><a href="#cb12-503" aria-hidden="true" tabindex="-1"></a>::: callout-caution</span>
<span id="cb12-504"><a href="#cb12-504" aria-hidden="true" tabindex="-1"></a><span class="fu"># White balancing fluorescence photographs</span></span>
<span id="cb12-505"><a href="#cb12-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-506"><a href="#cb12-506" aria-hidden="true" tabindex="-1"></a>Objectively white balancing a photograph of fluorescence is nearly impossible. After trying other approaches I have mostly settled into editing the colour in these photographs to "look right", i.e., matching my recollection of how the subject looked like when I photographed it. However, in some cases I use just a daylight balance and alternatively edit the colour to remove intense casts so as to increase the apparent colour range.</span>
<span id="cb12-507"><a href="#cb12-507" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-508"><a href="#cb12-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-509"><a href="#cb12-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-510"><a href="#cb12-510" aria-hidden="true" tabindex="-1"></a><span class="fu">## Further reading</span></span>
<span id="cb12-511"><a href="#cb12-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-512"><a href="#cb12-512" aria-hidden="true" tabindex="-1"></a>New books on digital photography techniques are regularly published, but few of them focus on the practice of photography rather than the principles and science behind. In my view, as in scientific photography consistency and reproducibility are a requirement, a deeper understanding is needed than for casual or even artistic photography. The book "Learning to Photograph" published in two volumes, even if slightly out-of-date, is my suggestion as a gentle but well informed introduction to digital photography <span class="co">[</span><span class="ot">@Banek2013;@Banek2013a</span><span class="co">]</span>. It was originally published in German <span class="co">[</span><span class="ot">@Banek2012;@Banek2012a</span><span class="co">]</span>.</span>
<span id="cb12-513"><a href="#cb12-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-514"><a href="#cb12-514" aria-hidden="true" tabindex="-1"></a>The books by Alfred Blaker, although written before the digital photography times, provide technical information and practical advice still relevant to scientific photography <span class="co">[</span><span class="ot">@Blaker1989</span><span class="co">]</span> and field photography <span class="co">[</span><span class="ot">@Blaker1976</span><span class="co">]</span>. His book on depth-of-field was reprinted in 2026 <span class="co">[</span><span class="ot">@Blaker1985</span><span class="co">]</span>. For French-speakers the book on macro-photography by Durand describes techniques comprehensively <span class="co">[</span><span class="ot">@Durand1977</span><span class="co">]</span>.</span>
<span id="cb12-515"><a href="#cb12-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-516"><a href="#cb12-516" aria-hidden="true" tabindex="-1"></a>Over the years Kodak has published and updated several technical handbooks, including about UV-B and NIR film photography <span class="co">[</span><span class="ot">e.g., @Kodak1972</span><span class="co">]</span>. They focus heavily on the use of photographic films, but some of the information about filters remains of some use.</span>
<span id="cb12-517"><a href="#cb12-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-518"><a href="#cb12-518" aria-hidden="true" tabindex="-1"></a>A more modern and very comprehensive account of photographic techniques used for scientific documentation, including UV, NIR and fluorescence imaging techniques was written by Enrico <span class="co">[</span><span class="ot">@Savazzi2011</span><span class="co">]</span>. Two other comprehensive books were published in recent years <span class="co">[</span><span class="ot">@Peres2017;@Peres2021</span><span class="co">]</span>. These three books cover a very broad set of techniques, and are best suited as reference or for studying scientific photography as a whole.</span>
<span id="cb12-519"><a href="#cb12-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-520"><a href="#cb12-520" aria-hidden="true" tabindex="-1"></a>Easier to read, more narrowly focused books, on UV photography <span class="co">[</span><span class="ot">@Prutchi2017</span><span class="co">]</span>, UV and NIR photography <span class="co">[</span><span class="ot">@Davies2017</span><span class="co">]</span>, photographying plants <span class="co">[</span><span class="ot">@Blacklock1990;@Davies2023</span><span class="co">]</span> and photographying the unseen <span class="co">[</span><span class="ot">@Davies2020</span><span class="co">]</span> are possible the best for readers already familiar with basic photography techniques.</span>
<span id="cb12-521"><a href="#cb12-521" aria-hidden="true" tabindex="-1"></a></span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://www.uv4plants.org">
<p>Uv4Plants Association</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 © 2012-2025 COST office and authors
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>